{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitchfork Says a Lot Despite Appearing to Say Very Little: A Sentiment Analysis of Music Reviews\n",
    "\n",
    "Music reviews can be tough to grasp. On one hand, you use them to figure out what to listen to. On the other hand, some of them can be esoteric, fatuous, and devoid of any meaning, despite appearing to say a lot. \n",
    "\n",
    "__*I was under the impression that [Pitchfork](https://www.pitchfork.com) could be described as such. It turns out I was wrong.*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary\n",
    "\n",
    "The aim of this project was to develop a robust technique for conducting sentiment analysis of text that can be both ambiguous and subjective. Ambiguity is a problem we tackle not only because of the inherent nature of the English language, but also because certain styles of writing sacrifice clarity for a turn of phrase that appears more impressive. Subjectivity enters the fray because of the nature of content being discussed. Without delving into the intricate philosophies of the matter, while you can discuss an art form objectively to a certain extent, after a point it becomes a matter of tastes. Two reviewers can offer opposing but perfectly valid critiques. This element cannot be ignored, because it means that we have to draw fine lines between fact, preference, and opinions. As such, I had to develop a technique that could accurately predict whether a reviewer enjoyed an album or not based on a pure sentiment analysis of the review.\n",
    "\n",
    "Given that there are fresh-out-of-the-box tools that will promptly give you an idea of sentiment of a piece of text, I had to beat certain benchmarks of accuracy and ROC-AUC score. I tried various degrees of models - I started with a fresh-out-of-the-box model, then moved onto a word-frequency based model, and then delved into the intricasies of the language and built a more low-level (and robust) model from scratch.\n",
    "\n",
    "I was able to beat the required benchmarks with a great deal of success. In addition to this, I was also able to take my methodology and convert it into an extremely pliable form that can be used as its own fresh-out-of-the-box sentiment analysis tool. \n",
    "\n",
    "\n",
    "_I will go into further detail later on._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procuring the Data\n",
    "\n",
    "I got my data from [Pitchfork's website](https://www.pitchfork.com). To obtain it, I built my own web-scraper that can be found below. Kudos to the web developer - it's rare to see a civilized website in the cold, harsh deserts of the internet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "```\n",
    "\n",
    "There were several components to building a web scraper of this nature. First, I had to determine what sorts of information I wanted.\n",
    "\n",
    "[This website will give you an idea of what each article looked like.](https://pitchfork.com/reviews/albums/18090-jon-hopkins-immunity/)\n",
    "\n",
    "I decided that I wanted - \n",
    "1. Artist\n",
    "2. Album\n",
    "3. Genres\n",
    "4. Score\n",
    "5. Author\n",
    "6. Time (or Date Posted)\n",
    "7. Abstract (the little block of text preceding the Article)\n",
    "8. The Article\n",
    "\n",
    "I built a function to procure this information from each review page.\n",
    "\n",
    "```Python\n",
    "def get_info(review_link):\n",
    "    \"\"\"\n",
    "    This function takes in a review link and returns all the relevant information on the page.\n",
    "    \"\"\"\n",
    "    \n",
    "    review_link = 'http://pitchfork.com' + review_link\n",
    "    review_html = requests.get(review_link)\n",
    "    review_soup = BeautifulSoup(review_html.text, 'html.parser')\n",
    "    \n",
    "    artist = 'N/A'\n",
    "    album = 'N/A'\n",
    "    genres = ['N/A']\n",
    "    score = 'N/A'\n",
    "    author = 'N/A'\n",
    "    time = 'N/A'\n",
    "    abstract = 'N/A'\n",
    "    article = 'N/A'\n",
    "    \n",
    "    try:\n",
    "        artist = review_soup.find(class_='artists').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        album = review_soup.find(class_='review-title').text.strip()      \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        genres = review_soup.find(class_='genre-list')\n",
    "        genres = [genres.text.strip() for genres in genres.find_all('li')]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        score = review_soup.find(class_='score').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        author = review_soup.find(class_='authors-detail__display-name').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        time = review_soup.find(class_='pub-date')['datetime'].strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        abstract = review_soup.find(class_='abstract').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        article = review_soup.find(class_='contents').text.strip()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return (artist, album, genres, score, author, time, abstract, article)  \n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "I then created a DataFrame that would reflect the information I was scraping.\n",
    "\n",
    "```Python\n",
    "columns = \"Artist Album Genre Score Author Time Abstract Article\".split()\n",
    "df = pd.DataFrame(columns=columns)\n",
    "```\n",
    "\n",
    "<br>\n",
    "And then the scraper itself.\n",
    "\n",
    "```Python\n",
    "URL = 'http://pitchfork.com/reviews/albums/?page='\n",
    "page_count = 1 # Which page should we start scraping from?\n",
    "\n",
    "temp_url = URL + str(page_count)\n",
    "html = requests.get(temp_url)\n",
    "i = 0\n",
    "\n",
    "while html.status_code != 404: ## While the page I requested actually exists\n",
    "    \n",
    "    soup  = BeautifulSoup(html.text, 'html.parser')\n",
    "    \n",
    "    for review in soup.find_all(class_='review'): ## Go through every review on the page.\n",
    "        \n",
    "        review_link = review.find('a')['href']\n",
    "        \n",
    "        artist, album, genres, score, author, time, abstract, article = get_info(review_link)\n",
    "        df.loc[i] = {'Artist': artist, 'Album': album, 'Genre': genres, 'Score': score, 'Author': author, \\\n",
    "                        'Time': time, 'Abstract': abstract, 'Article': article}\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        ## Save the file every 100 reviews.\n",
    "        if i % 100 == 0:\n",
    "            df.to_csv('../data/Pitchfork Reviews.csv')\n",
    "    \n",
    "    ## A little indicator I can use to get updates on my scraper\n",
    "    print('Just hit the ' + str(i) + 'th review!')\n",
    "    \n",
    "    page_count += 1\n",
    "    temp_url = URL + str(page_count)\n",
    "    html = requests.get(temp_url)\n",
    "\n",
    "    print(\"We're done! Your web scraper collected \" + str(i) + \" reviews!\")\n",
    "    \n",
    "    print(\"Dropping\", str(df.shape[0] - df.dropna().shape[0]), \"Values.\")\n",
    "    df = df.dropna()\n",
    "    df.to_csv('Pitchfork Reviews.csv')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Importing the necessary packages.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn-white')\n",
    "# Increase figure size\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.rcParams['font.size'] = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I renamed Time to Date and decided to use it to index my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Album</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Score</th>\n",
       "      <th>Author</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Japanese Breakfast</td>\n",
       "      <td>Soft Sounds From Another Planet</td>\n",
       "      <td>Rock</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Nathan Reese</td>\n",
       "      <td>Inspired by the cosmos, Japanese Breakfast’s M...</td>\n",
       "      <td>Michelle Zauner’s first album as Japanese Brea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Mura Masa</td>\n",
       "      <td>Mura Masa</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Eve Barlow</td>\n",
       "      <td>Alex Crossan’s debut album is a love letter to...</td>\n",
       "      <td>Oscar Wilde once said, “The man who can domina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Coca Leaf</td>\n",
       "      <td>Deep Marble Sunrise</td>\n",
       "      <td>Experimental</td>\n",
       "      <td>7.1</td>\n",
       "      <td>Paul Thompson</td>\n",
       "      <td>Featuring members of Merchandise, the Ukiah Dr...</td>\n",
       "      <td>Dig your way through the sprawling catalogs of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Claude Speeed</td>\n",
       "      <td>Infinity Ultra</td>\n",
       "      <td>Electronic</td>\n",
       "      <td>7.4</td>\n",
       "      <td>Philip Sherburne</td>\n",
       "      <td>With songs that travel great distances between...</td>\n",
       "      <td>When the Scottish electronic musician Claude S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-17</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Kaleidoscope EP</td>\n",
       "      <td>Rock</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Jamieson Cox</td>\n",
       "      <td>Held up by two good-to-great songs, the lightw...</td>\n",
       "      <td>Coldplay are nearing the end of a restless dec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Artist                            Album         Genre  \\\n",
       "Date                                                                            \n",
       "2017-07-18  Japanese Breakfast  Soft Sounds From Another Planet          Rock   \n",
       "2017-07-18           Mura Masa                        Mura Masa    Electronic   \n",
       "2017-07-18           Coca Leaf              Deep Marble Sunrise  Experimental   \n",
       "2017-07-18       Claude Speeed                   Infinity Ultra    Electronic   \n",
       "2017-07-17            Coldplay                  Kaleidoscope EP          Rock   \n",
       "\n",
       "            Score            Author  \\\n",
       "Date                                  \n",
       "2017-07-18    8.0      Nathan Reese   \n",
       "2017-07-18    7.7        Eve Barlow   \n",
       "2017-07-18    7.1     Paul Thompson   \n",
       "2017-07-18    7.4  Philip Sherburne   \n",
       "2017-07-17    5.8      Jamieson Cox   \n",
       "\n",
       "                                                     Abstract  \\\n",
       "Date                                                            \n",
       "2017-07-18  Inspired by the cosmos, Japanese Breakfast’s M...   \n",
       "2017-07-18  Alex Crossan’s debut album is a love letter to...   \n",
       "2017-07-18  Featuring members of Merchandise, the Ukiah Dr...   \n",
       "2017-07-18  With songs that travel great distances between...   \n",
       "2017-07-17  Held up by two good-to-great songs, the lightw...   \n",
       "\n",
       "                                                      Article  \n",
       "Date                                                           \n",
       "2017-07-18  Michelle Zauner’s first album as Japanese Brea...  \n",
       "2017-07-18  Oscar Wilde once said, “The man who can domina...  \n",
       "2017-07-18  Dig your way through the sprawling catalogs of...  \n",
       "2017-07-18  When the Scottish electronic musician Claude S...  \n",
       "2017-07-17  Coldplay are nearing the end of a restless dec...  "
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/Pitchfork Reviews.csv')\n",
    "df['Date'] = pd.to_datetime(df.Time).dt.date\n",
    "df = df.drop(['Time', 'Unnamed: 0'], axis=1).set_index(['Date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14518 entries, 2017-07-18 to 1999-01-12\n",
      "Data columns (total 7 columns):\n",
      "Artist      14517 non-null object\n",
      "Album       14515 non-null object\n",
      "Genre       14518 non-null object\n",
      "Score       14518 non-null float64\n",
      "Author      14518 non-null object\n",
      "Abstract    14205 non-null object\n",
      "Article     14517 non-null object\n",
      "dtypes: float64(1), object(6)\n",
      "memory usage: 907.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping all duplicate reviews and any any reviews that don't have the necessary components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates().dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rock                                                  5673\n",
       "Electronic                                            1840\n",
       "Rap                                                   1175\n",
       "Electronic', 'Rock                                     972\n",
       "Pop/R&B                                                797\n",
       "Experimental', 'Rock                                   744\n",
       "Experimental                                           529\n",
       "Folk/Country                                           483\n",
       "Metal', 'Rock                                          305\n",
       "Metal                                                  287\n",
       "Electronic', 'Pop/R&B                                  147\n",
       "Jazz                                                   134\n",
       "Global                                                  97\n",
       "Pop/R&B', 'Rap                                          86\n",
       "Electronic', 'Experimental', 'Rock                      86\n",
       "Pop/R&B', 'Rock                                         74\n",
       "Electronic', 'Jazz                                      65\n",
       "Electronic', 'Rap                                       50\n",
       "Experimental', 'Jazz                                    43\n",
       "Electronic', 'Experimental                              41\n",
       "Rap', 'Rock                                             40\n",
       "Global', 'Pop/R&B                                       31\n",
       "Folk/Country', 'Pop/R&B                                 30\n",
       "Folk/Country', 'Rock                                    29\n",
       "Experimental', 'Metal', 'Rock                           23\n",
       "Jazz', 'Pop/R&B                                         18\n",
       "Electronic', 'Metal', 'Rock                             18\n",
       "Electronic', 'Jazz', 'Pop/R&B                           17\n",
       "Electronic', 'Global                                    17\n",
       "Jazz', 'Metal                                           17\n",
       "                                                      ... \n",
       "Electronic', 'Rock', 'Experimental', 'Global             1\n",
       "Jazz', 'Rock', 'Electronic                               1\n",
       "Experimental', 'Folk/Country', 'Pop/R&B', 'Rock          1\n",
       "Folk/Country', 'Jazz                                     1\n",
       "Global', 'Pop/R&B', 'Electronic', 'Rock                  1\n",
       "Folk/Country', 'Experimental', 'Rock', 'Electronic       1\n",
       "Rap', 'Jazz                                              1\n",
       "Jazz', 'Experimental', 'Folk/Country                     1\n",
       "Folk/Country', 'Pop/R&B', 'Rap                           1\n",
       "Electronic', 'Experimental', 'Pop/R&B', 'Rock            1\n",
       "Electronic', 'Experimental', 'Rap', 'Rock                1\n",
       "Electronic', 'Global', 'Jazz                             1\n",
       "Experimental', 'Global', 'Rock                           1\n",
       "Jazz', 'Global', 'Rap                                    1\n",
       "Electronic', 'Pop/R&B', 'Rap                             1\n",
       "Electronic', 'Metal', 'Rap', 'Rock                       1\n",
       "Electronic', 'Experimental', 'Rap                        1\n",
       "Metal', 'Rock', 'Folk/Country                            1\n",
       "Global', 'Rap                                            1\n",
       "Experimental', 'Electronic                               1\n",
       "Jazz', 'Pop/R&B', 'Rap                                   1\n",
       "Electronic', 'Global', 'Rap                              1\n",
       "Rock', 'Folk/Country', 'Pop/R&B                          1\n",
       "Rap', 'Electronic', 'Jazz', 'Pop/R&B                     1\n",
       "Experimental', 'Folk/Country', 'Jazz                     1\n",
       "Folk/Country', 'Jazz', 'Rock                             1\n",
       "Experimental', 'Metal', 'Electronic                      1\n",
       "Folk/Country', 'Rock', 'Pop/R&B                          1\n",
       "Metal', 'Pop/R&B                                         1\n",
       "Metal', 'Rap', 'Rock                                     1\n",
       "Name: Genre, Length: 126, dtype: int64"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dummy columns for the various genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_genre(x):\n",
    "    return x.replace(\"'\", ' ').replace(',', ' ').split()\n",
    "\n",
    "df.Genre = df.Genre.apply(get_genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rock',\n",
       " 'Electronic',\n",
       " 'Experimental',\n",
       " 'Metal',\n",
       " 'Pop/R&B',\n",
       " 'Rap',\n",
       " 'Global',\n",
       " 'Jazz',\n",
       " 'Folk/Country']"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = []\n",
    "\n",
    "def get_genre_list(x):\n",
    "    global genres\n",
    "    genres += [item for item in x if item not in genres]\n",
    "    \n",
    "df.Genre.apply(get_genre_list)\n",
    "genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Album</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Score</th>\n",
       "      <th>Author</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Article</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Electronic</th>\n",
       "      <th>Experimental</th>\n",
       "      <th>Metal</th>\n",
       "      <th>Pop/R&amp;B</th>\n",
       "      <th>Rap</th>\n",
       "      <th>Global</th>\n",
       "      <th>Jazz</th>\n",
       "      <th>Folk/Country</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Japanese Breakfast</td>\n",
       "      <td>Soft Sounds From Another Planet</td>\n",
       "      <td>[Rock]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Nathan Reese</td>\n",
       "      <td>Inspired by the cosmos, Japanese Breakfast’s M...</td>\n",
       "      <td>Michelle Zauner’s first album as Japanese Brea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Mura Masa</td>\n",
       "      <td>Mura Masa</td>\n",
       "      <td>[Electronic]</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Eve Barlow</td>\n",
       "      <td>Alex Crossan’s debut album is a love letter to...</td>\n",
       "      <td>Oscar Wilde once said, “The man who can domina...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Coca Leaf</td>\n",
       "      <td>Deep Marble Sunrise</td>\n",
       "      <td>[Experimental]</td>\n",
       "      <td>7.1</td>\n",
       "      <td>Paul Thompson</td>\n",
       "      <td>Featuring members of Merchandise, the Ukiah Dr...</td>\n",
       "      <td>Dig your way through the sprawling catalogs of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Claude Speeed</td>\n",
       "      <td>Infinity Ultra</td>\n",
       "      <td>[Electronic]</td>\n",
       "      <td>7.4</td>\n",
       "      <td>Philip Sherburne</td>\n",
       "      <td>With songs that travel great distances between...</td>\n",
       "      <td>When the Scottish electronic musician Claude S...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-17</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Kaleidoscope EP</td>\n",
       "      <td>[Rock]</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Jamieson Cox</td>\n",
       "      <td>Held up by two good-to-great songs, the lightw...</td>\n",
       "      <td>Coldplay are nearing the end of a restless dec...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Artist                            Album  \\\n",
       "Date                                                              \n",
       "2017-07-18  Japanese Breakfast  Soft Sounds From Another Planet   \n",
       "2017-07-18           Mura Masa                        Mura Masa   \n",
       "2017-07-18           Coca Leaf              Deep Marble Sunrise   \n",
       "2017-07-18       Claude Speeed                   Infinity Ultra   \n",
       "2017-07-17            Coldplay                  Kaleidoscope EP   \n",
       "\n",
       "                     Genre  Score            Author  \\\n",
       "Date                                                  \n",
       "2017-07-18          [Rock]    8.0      Nathan Reese   \n",
       "2017-07-18    [Electronic]    7.7        Eve Barlow   \n",
       "2017-07-18  [Experimental]    7.1     Paul Thompson   \n",
       "2017-07-18    [Electronic]    7.4  Philip Sherburne   \n",
       "2017-07-17          [Rock]    5.8      Jamieson Cox   \n",
       "\n",
       "                                                     Abstract  \\\n",
       "Date                                                            \n",
       "2017-07-18  Inspired by the cosmos, Japanese Breakfast’s M...   \n",
       "2017-07-18  Alex Crossan’s debut album is a love letter to...   \n",
       "2017-07-18  Featuring members of Merchandise, the Ukiah Dr...   \n",
       "2017-07-18  With songs that travel great distances between...   \n",
       "2017-07-17  Held up by two good-to-great songs, the lightw...   \n",
       "\n",
       "                                                      Article  Rock  \\\n",
       "Date                                                                  \n",
       "2017-07-18  Michelle Zauner’s first album as Japanese Brea...     1   \n",
       "2017-07-18  Oscar Wilde once said, “The man who can domina...     0   \n",
       "2017-07-18  Dig your way through the sprawling catalogs of...     0   \n",
       "2017-07-18  When the Scottish electronic musician Claude S...     0   \n",
       "2017-07-17  Coldplay are nearing the end of a restless dec...     1   \n",
       "\n",
       "            Electronic  Experimental  Metal  Pop/R&B  Rap  Global  Jazz  \\\n",
       "Date                                                                      \n",
       "2017-07-18           0             0      0        0    0       0     0   \n",
       "2017-07-18           1             0      0        0    0       0     0   \n",
       "2017-07-18           0             1      0        0    0       0     0   \n",
       "2017-07-18           1             0      0        0    0       0     0   \n",
       "2017-07-17           0             0      0        0    0       0     0   \n",
       "\n",
       "            Folk/Country  \n",
       "Date                      \n",
       "2017-07-18             0  \n",
       "2017-07-18             0  \n",
       "2017-07-18             0  \n",
       "2017-07-18             0  \n",
       "2017-07-17             0  "
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for genre in genres:\n",
    "    df[genre] = df.Genre.apply(lambda x : 1 if genre in x else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a binary score that I use as my predictor - if the review is good (score above 5.0), the field gets a 1. Otherwise it gets a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Album</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Score</th>\n",
       "      <th>Author</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Article</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Electronic</th>\n",
       "      <th>Experimental</th>\n",
       "      <th>Metal</th>\n",
       "      <th>Pop/R&amp;B</th>\n",
       "      <th>Rap</th>\n",
       "      <th>Global</th>\n",
       "      <th>Jazz</th>\n",
       "      <th>Folk/Country</th>\n",
       "      <th>Score_Binary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Japanese Breakfast</td>\n",
       "      <td>Soft Sounds From Another Planet</td>\n",
       "      <td>[Rock]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Nathan Reese</td>\n",
       "      <td>Inspired by the cosmos, Japanese Breakfast’s M...</td>\n",
       "      <td>Michelle Zauner’s first album as Japanese Brea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Mura Masa</td>\n",
       "      <td>Mura Masa</td>\n",
       "      <td>[Electronic]</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Eve Barlow</td>\n",
       "      <td>Alex Crossan’s debut album is a love letter to...</td>\n",
       "      <td>Oscar Wilde once said, “The man who can domina...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Coca Leaf</td>\n",
       "      <td>Deep Marble Sunrise</td>\n",
       "      <td>[Experimental]</td>\n",
       "      <td>7.1</td>\n",
       "      <td>Paul Thompson</td>\n",
       "      <td>Featuring members of Merchandise, the Ukiah Dr...</td>\n",
       "      <td>Dig your way through the sprawling catalogs of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Claude Speeed</td>\n",
       "      <td>Infinity Ultra</td>\n",
       "      <td>[Electronic]</td>\n",
       "      <td>7.4</td>\n",
       "      <td>Philip Sherburne</td>\n",
       "      <td>With songs that travel great distances between...</td>\n",
       "      <td>When the Scottish electronic musician Claude S...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-17</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Kaleidoscope EP</td>\n",
       "      <td>[Rock]</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Jamieson Cox</td>\n",
       "      <td>Held up by two good-to-great songs, the lightw...</td>\n",
       "      <td>Coldplay are nearing the end of a restless dec...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Artist                            Album  \\\n",
       "Date                                                              \n",
       "2017-07-18  Japanese Breakfast  Soft Sounds From Another Planet   \n",
       "2017-07-18           Mura Masa                        Mura Masa   \n",
       "2017-07-18           Coca Leaf              Deep Marble Sunrise   \n",
       "2017-07-18       Claude Speeed                   Infinity Ultra   \n",
       "2017-07-17            Coldplay                  Kaleidoscope EP   \n",
       "\n",
       "                     Genre  Score            Author  \\\n",
       "Date                                                  \n",
       "2017-07-18          [Rock]    8.0      Nathan Reese   \n",
       "2017-07-18    [Electronic]    7.7        Eve Barlow   \n",
       "2017-07-18  [Experimental]    7.1     Paul Thompson   \n",
       "2017-07-18    [Electronic]    7.4  Philip Sherburne   \n",
       "2017-07-17          [Rock]    5.8      Jamieson Cox   \n",
       "\n",
       "                                                     Abstract  \\\n",
       "Date                                                            \n",
       "2017-07-18  Inspired by the cosmos, Japanese Breakfast’s M...   \n",
       "2017-07-18  Alex Crossan’s debut album is a love letter to...   \n",
       "2017-07-18  Featuring members of Merchandise, the Ukiah Dr...   \n",
       "2017-07-18  With songs that travel great distances between...   \n",
       "2017-07-17  Held up by two good-to-great songs, the lightw...   \n",
       "\n",
       "                                                      Article  Rock  \\\n",
       "Date                                                                  \n",
       "2017-07-18  Michelle Zauner’s first album as Japanese Brea...     1   \n",
       "2017-07-18  Oscar Wilde once said, “The man who can domina...     0   \n",
       "2017-07-18  Dig your way through the sprawling catalogs of...     0   \n",
       "2017-07-18  When the Scottish electronic musician Claude S...     0   \n",
       "2017-07-17  Coldplay are nearing the end of a restless dec...     1   \n",
       "\n",
       "            Electronic  Experimental  Metal  Pop/R&B  Rap  Global  Jazz  \\\n",
       "Date                                                                      \n",
       "2017-07-18           0             0      0        0    0       0     0   \n",
       "2017-07-18           1             0      0        0    0       0     0   \n",
       "2017-07-18           0             1      0        0    0       0     0   \n",
       "2017-07-18           1             0      0        0    0       0     0   \n",
       "2017-07-17           0             0      0        0    0       0     0   \n",
       "\n",
       "            Folk/Country  Score_Binary  \n",
       "Date                                    \n",
       "2017-07-18             0             1  \n",
       "2017-07-18             0             1  \n",
       "2017-07-18             0             1  \n",
       "2017-07-18             0             1  \n",
       "2017-07-17             0             1  "
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Score_Binary'] = df.Score.apply(lambda x : 1 if x >= 5 else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Model using TextBlob\n",
    "\n",
    "The first modelling technique I will attempt to use makes some naive assumptions - \n",
    "\n",
    "+ The Pitchfork reviewers understand scaling well.\n",
    "\n",
    "The scaling fallacy isn't restricted to Pitchfork reviewers. Most people suffer from it. The issue is that people will often, on a scale between 1 and 10, consider ~7 an average. This fallacy is derived from the way school tests are scored, where everyone roughly scores around a 70. However, in a well scaled distribution, the average should be a 5. How does this translate to reviews? It means that a score of 5.0 is average or mediocre. Anything above a 5.0 is on the side of good, and anything below a 5.0 is on the side of bad.\n",
    "\n",
    "+ Pitchfork reviews may have unbalanced classes.\n",
    "\n",
    "An interesting problem to deal with is the fact that Pitchfork's reviews won't be distributed very evenly because it's likely that they're reviewing albums that are interesting to the public or musically stimulating in some manner. Therefore, it's fair that we may not see too many scores under 5. This is the unbalanced classes problem. We won't be dealing with that at this stage.\n",
    "\n",
    "+ TextBlob's sentiment analyzer is complex and can understand nuances in the English language.\n",
    "\n",
    "It's probably naive to assume this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['Text'] = df['Abstract'] + ' ' + df['Article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_sent_score = df[['Text', 'Score', 'Score_Binary']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ExSidius/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n",
      "/Users/ExSidius/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "      <th>Score_Binary</th>\n",
       "      <th>Naive_Sent_Score</th>\n",
       "      <th>Naive_Sent_Score_Binary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Inspired by the cosmos, Japanese Breakfast’s M...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Alex Crossan’s debut album is a love letter to...</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Featuring members of Merchandise, the Ukiah Dr...</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>With songs that travel great distances between...</td>\n",
       "      <td>7.4</td>\n",
       "      <td>1</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-17</th>\n",
       "      <td>Held up by two good-to-great songs, the lightw...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Text  Score  \\\n",
       "Date                                                                   \n",
       "2017-07-18  Inspired by the cosmos, Japanese Breakfast’s M...    8.0   \n",
       "2017-07-18  Alex Crossan’s debut album is a love letter to...    7.7   \n",
       "2017-07-18  Featuring members of Merchandise, the Ukiah Dr...    7.1   \n",
       "2017-07-18  With songs that travel great distances between...    7.4   \n",
       "2017-07-17  Held up by two good-to-great songs, the lightw...    5.8   \n",
       "\n",
       "            Score_Binary  Naive_Sent_Score  Naive_Sent_Score_Binary  \n",
       "Date                                                                 \n",
       "2017-07-18             1               5.7                        1  \n",
       "2017-07-18             1               6.0                        1  \n",
       "2017-07-18             1               5.5                        1  \n",
       "2017-07-18             1               6.1                        1  \n",
       "2017-07-17             1               5.9                        1  "
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_naive_sent_score(x):\n",
    "    return round((TextBlob(x).sentiment.polarity + 1) * 10 / 2, 1)\n",
    "\n",
    "naive_sent_score['Naive_Sent_Score'] = naive_sent_score.Text.apply(get_naive_sent_score)\n",
    "naive_sent_score['Naive_Sent_Score_Binary'] = naive_sent_score['Naive_Sent_Score'].apply(lambda x : 1 if x >= 5 else 0)\n",
    "naive_sent_score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92333709131905295"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(naive_sent_score['Score_Binary'], naive_sent_score['Naive_Sent_Score_Binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69425091112112025"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(naive_sent_score['Score_Binary'], naive_sent_score['Naive_Sent_Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a moderately good estimation, but it still isn't ideal. High accuracy, but terrible ROC-AUC Score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF and XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my second model, I am going to use TFIDF (which looks at weighted frequency of words) and an XGBoost Classifier, which is a powerful fresh-out-of-the-box modelling technique. I won't spend too much time tuning parameters, given that I just want to get an idea of how the modelling technique does based off of simple word frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc='progress-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "copy = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    stop_words = set(stopwords.words('english') + list(string.punctuation))\n",
    "    lemma = WordNetLemmatizer()\n",
    "    try:\n",
    "        tokens = word_tokenize(text.lower())\n",
    "        tokens = [t for t in tokens if t not in stop_words]\n",
    "        tokens = [re.sub(re_punct, '', t) for t in tokens]\n",
    "        tokens = [t for t in tokens if len(t) > 2]\n",
    "        tokens = [lemma.lemmatize(t) for t in tokens]\n",
    "        if len(tokens) == 0:\n",
    "            return None\n",
    "        else:\n",
    "            return ' '.join(tokens)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ExSidius/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "copy['Tokenized'] = copy['Text'].apply(preprocess)\n",
    "copy = copy[copy['Tokenized'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>Album</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Score</th>\n",
       "      <th>Author</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Article</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Electronic</th>\n",
       "      <th>Experimental</th>\n",
       "      <th>Metal</th>\n",
       "      <th>Pop/R&amp;B</th>\n",
       "      <th>Rap</th>\n",
       "      <th>Global</th>\n",
       "      <th>Jazz</th>\n",
       "      <th>Folk/Country</th>\n",
       "      <th>Score_Binary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Japanese Breakfast</td>\n",
       "      <td>Soft Sounds From Another Planet</td>\n",
       "      <td>[Rock]</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Nathan Reese</td>\n",
       "      <td>Inspired by the cosmos, Japanese Breakfast’s M...</td>\n",
       "      <td>Michelle Zauner’s first album as Japanese Brea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Inspired by the cosmos, Japanese Breakfast’s M...</td>\n",
       "      <td>inspired cosmos japanese breakfast michelle za...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Mura Masa</td>\n",
       "      <td>Mura Masa</td>\n",
       "      <td>[Electronic]</td>\n",
       "      <td>7.7</td>\n",
       "      <td>Eve Barlow</td>\n",
       "      <td>Alex Crossan’s debut album is a love letter to...</td>\n",
       "      <td>Oscar Wilde once said, “The man who can domina...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Alex Crossan’s debut album is a love letter to...</td>\n",
       "      <td>alex crossan debut album love letter multicult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Coca Leaf</td>\n",
       "      <td>Deep Marble Sunrise</td>\n",
       "      <td>[Experimental]</td>\n",
       "      <td>7.1</td>\n",
       "      <td>Paul Thompson</td>\n",
       "      <td>Featuring members of Merchandise, the Ukiah Dr...</td>\n",
       "      <td>Dig your way through the sprawling catalogs of...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Featuring members of Merchandise, the Ukiah Dr...</td>\n",
       "      <td>featuring member merchandise ukiah drag unifor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Claude Speeed</td>\n",
       "      <td>Infinity Ultra</td>\n",
       "      <td>[Electronic]</td>\n",
       "      <td>7.4</td>\n",
       "      <td>Philip Sherburne</td>\n",
       "      <td>With songs that travel great distances between...</td>\n",
       "      <td>When the Scottish electronic musician Claude S...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>With songs that travel great distances between...</td>\n",
       "      <td>song travel great distance pole ambient noise ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-17</th>\n",
       "      <td>Coldplay</td>\n",
       "      <td>Kaleidoscope EP</td>\n",
       "      <td>[Rock]</td>\n",
       "      <td>5.8</td>\n",
       "      <td>Jamieson Cox</td>\n",
       "      <td>Held up by two good-to-great songs, the lightw...</td>\n",
       "      <td>Coldplay are nearing the end of a restless dec...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Held up by two good-to-great songs, the lightw...</td>\n",
       "      <td>held two goodtogreat song lightweight coldplay...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Artist                            Album  \\\n",
       "Date                                                              \n",
       "2017-07-18  Japanese Breakfast  Soft Sounds From Another Planet   \n",
       "2017-07-18           Mura Masa                        Mura Masa   \n",
       "2017-07-18           Coca Leaf              Deep Marble Sunrise   \n",
       "2017-07-18       Claude Speeed                   Infinity Ultra   \n",
       "2017-07-17            Coldplay                  Kaleidoscope EP   \n",
       "\n",
       "                     Genre  Score            Author  \\\n",
       "Date                                                  \n",
       "2017-07-18          [Rock]    8.0      Nathan Reese   \n",
       "2017-07-18    [Electronic]    7.7        Eve Barlow   \n",
       "2017-07-18  [Experimental]    7.1     Paul Thompson   \n",
       "2017-07-18    [Electronic]    7.4  Philip Sherburne   \n",
       "2017-07-17          [Rock]    5.8      Jamieson Cox   \n",
       "\n",
       "                                                     Abstract  \\\n",
       "Date                                                            \n",
       "2017-07-18  Inspired by the cosmos, Japanese Breakfast’s M...   \n",
       "2017-07-18  Alex Crossan’s debut album is a love letter to...   \n",
       "2017-07-18  Featuring members of Merchandise, the Ukiah Dr...   \n",
       "2017-07-18  With songs that travel great distances between...   \n",
       "2017-07-17  Held up by two good-to-great songs, the lightw...   \n",
       "\n",
       "                                                      Article  Rock  \\\n",
       "Date                                                                  \n",
       "2017-07-18  Michelle Zauner’s first album as Japanese Brea...     1   \n",
       "2017-07-18  Oscar Wilde once said, “The man who can domina...     0   \n",
       "2017-07-18  Dig your way through the sprawling catalogs of...     0   \n",
       "2017-07-18  When the Scottish electronic musician Claude S...     0   \n",
       "2017-07-17  Coldplay are nearing the end of a restless dec...     1   \n",
       "\n",
       "            Electronic  Experimental  Metal  Pop/R&B  Rap  Global  Jazz  \\\n",
       "Date                                                                      \n",
       "2017-07-18           0             0      0        0    0       0     0   \n",
       "2017-07-18           1             0      0        0    0       0     0   \n",
       "2017-07-18           0             1      0        0    0       0     0   \n",
       "2017-07-18           1             0      0        0    0       0     0   \n",
       "2017-07-17           0             0      0        0    0       0     0   \n",
       "\n",
       "            Folk/Country  Score_Binary  \\\n",
       "Date                                     \n",
       "2017-07-18             0             1   \n",
       "2017-07-18             0             1   \n",
       "2017-07-18             0             1   \n",
       "2017-07-18             0             1   \n",
       "2017-07-17             0             1   \n",
       "\n",
       "                                                         Text  \\\n",
       "Date                                                            \n",
       "2017-07-18  Inspired by the cosmos, Japanese Breakfast’s M...   \n",
       "2017-07-18  Alex Crossan’s debut album is a love letter to...   \n",
       "2017-07-18  Featuring members of Merchandise, the Ukiah Dr...   \n",
       "2017-07-18  With songs that travel great distances between...   \n",
       "2017-07-17  Held up by two good-to-great songs, the lightw...   \n",
       "\n",
       "                                                    Tokenized  \n",
       "Date                                                           \n",
       "2017-07-18  inspired cosmos japanese breakfast michelle za...  \n",
       "2017-07-18  alex crossan debut album love letter multicult...  \n",
       "2017-07-18  featuring member merchandise ukiah drag unifor...  \n",
       "2017-07-18  song travel great distance pole ambient noise ...  \n",
       "2017-07-17  held two goodtogreat song lightweight coldplay...  "
      ]
     },
     "execution_count": 449,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "to_drop = 'Date Artist Album Genre Score Author Abstract Article Text Tokenized Score_Binary'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = copy.Tokenized.tolist() \n",
    "y = copy['Score_Binary']\n",
    "vectorizer = TfidfVectorizer(min_df=0.1, max_df=0.8) # Term Frequency Inverse Document Frequency Vectorizer\n",
    "X = vectorizer.fit_transform(texts)\n",
    "X_df = pd.concat([copy.reset_index(), pd.DataFrame(X.todense())], axis=1).drop(to_drop, axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.2, random_state=42) # Train Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.4 s, sys: 57.2 ms, total: 13.4 s\n",
      "Wall time: 13.4 s\n",
      "Accuracy: 93.31 %\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "%time xgb.fit(X_train, y_train)\n",
    "print('Accuracy:', round(xgb.score(X_test, y_test) * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC-ROC Score: 78.05 %\n"
     ]
    }
   ],
   "source": [
    "preds = xgb.predict_proba(X_test)\n",
    "print('AUC-ROC Score:', round(roc_auc_score(y_test, [item[1] for item in preds]) * 100, 2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Some more Advanced NLP\n",
    "\n",
    "In this section, I plan to do plenty of low-level NLP. This includes - \n",
    "\n",
    "1. Removing stop words and punctuation.\n",
    "\n",
    "2. Filtering by speech tags in order to keep adjectives, adverbs, and verbs.\n",
    "\n",
    "3. Lemmatizing text (without Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['Abstract'] + ' ' + df['Article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process(x):\n",
    "    \"\"\"Gets adjectives, adverbs, and verbs.\"\"\"\n",
    "    import nltk\n",
    "    import string\n",
    "    from nltk import word_tokenize\n",
    "    from nltk.corpus import stopwords\n",
    "    \n",
    "    tokens = word_tokenize(x)\n",
    "    stop_words = set(stopwords.words('english') + list(string.punctuation))\n",
    "    \n",
    "    filtered = list(set(tokens) - stop_words)\n",
    "    \n",
    "    word_types = ['J', 'R', 'V']\n",
    "    tagged = nltk.pos_tag(filtered)\n",
    "    \n",
    "    relevant_words = []\n",
    "    \n",
    "    for word, tag in tagged:\n",
    "        for word_type in word_types:\n",
    "            if word_type == tag[0]:\n",
    "                relevant_words.append(word)\n",
    "    \n",
    "    lemma = WordNetLemmatizer()\n",
    "    \n",
    "    return [lemma.lemmatize(word) for word in relevant_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of text before processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Inspired by the cosmos, Japanese Breakfast’s Michelle Zauner addresses life on Earth. Her voice shines over melancholic arrangements, evoking Pacific Northwest indie rock as much as shoegaze. Michelle Zauner’s first album as Japanese Breakfast, 2016’s Psychopomp, was a meditation on grief in the wake of her mother’s death from cancer, as well as a raw portrayal of sexuality and heartache. That these subjects could coexist in the same space isn’t unusual (death and sex often mix, especially at the edge of human experience), but Zauner’s gift for connecting specific details to simple metaphor was uniquely affecting. “The dog’s confused/She just paces ‘round all day/She’s sniffing at your empty room,” she sang on “In Heaven.” Then, on “Jane Cum”: “Soulless animal keep feeding on my meat/All my tiny bones between your teeth.”\\nWhile Psychopomp focused on the most intimate human experiences, her new album, Soft Sounds From Another Planet, uses big guitars and melancholic arrangements to address life on Earth, but it calls upon the cosmos for its perspective. Zauner has said that Soft Sounds... began as a concept album—“a science fiction musical”—but the idea never panned out. Still, there’s a sheen to the project that suggests the initial inspiration made it into the album’s production (there are wordless, atmospheric interludes), as well as numerous references to other worlds.\\n“Machinist,” the first single, is the biggest leap forward in terms of sound and one of the album’s best songs. The song begins with the voice of a woman speaking to a computer: “Was it always this way and I just couldn’t see it?,” she asks, falling for her digital lover. Then, in a whirl of keyboards and Auto-Tune, the track explodes as a kind of new age disco anthem. “I just wanted it all,” she sings.\\nOn the title track, Zauner looks to the heavens for help with a self-destructive partner. “I wish I could keep you from abusing yourself for no reason at all,” she sings. Though Zauner searches to other worlds for help, the only answer she gets is reverb. (I'm reminded of a Calvin & Hobbes strips when Calvin screams to the abyss.) On “Boyish,” an old song repurposed from her days in the rock band Little Big League, Zauner brings things back down to earth. “I can’t get you off my mind, I can’t get you off in general,” goes the instantly iconic chorus, now backed by a melody that would make Roy Orbison grin. The sentiment encapsulates Zauner’s sensibilities: uncomfortably personal, unpretentiously profound.\\nNowhere has Zauner’s approach ever been clearer than when the band opened for the newly-reunited Slowdive earlier this year. It was a pairing that at once justified early comparisons between Japanese Breakfast and shoegaze greats, but also inadvertently highlighted the differences between the two groups. Where Slowdive set their vocals back in the mix, their voices just another thread in a tapestry of sound, that is not Zauner’s way. Instead, Zauner and co-producer Craig Hendrix make sure the words are never lost in the mix, but rather driving it. As much as shoegaze and C86 bands, Zauner’s music evokes the Pacific Northwest indie rock that Zauner grew up with in Oregon before moving to Philly; “Road Head” rings with the strip-mall mythologizing of Built to Spill’s “Car,” and there’s a hint of Modest Mouse’s “Sleepwalking” on torch songs like “Boyish.”\\nAs with Psychopomp, the album’s most powerful moments come when Zauner examines seeming contradictions that actually aren’t or shouldn’t be. The opening track, “Diving Woman,” flirts with domesticity as a way to normalize her life. “I want to be a woman of regimen,” she sings, “A bride in her home state/A diving woman of Jeju-do.” Jeju is an island in Zauner’s native South Korea with a traditionally matriarchal society, where female free divers were the breadwinners and heads of household. Here, Zauner has reimagined an age-old trope on her own terms. For the album, she told Out, “I create my own experiences and communities that are largely rooted with queer people, women, non-binary people, all different races.”\\nWith “The Body Is a Blade,” Zauner’s fascination with duality comes across most pointedly. “The body is a blade that moves while your brain is writhing/Knuckled under pain, you mourn but your blood is flowing,” she sings. Though Zauner is still grieving, her body has its own ideas. And even as Japanese Breakfast turn to the stars, Zauner’s best moments are rooted in the here and now.\""
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An example of text after processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reimagined',\n",
       " 'back',\n",
       " 'shoegaze',\n",
       " 'dog',\n",
       " 'Japanese',\n",
       " 'musical',\n",
       " 'highlighted',\n",
       " 'mythologizing',\n",
       " '‘',\n",
       " 'portrayal',\n",
       " 'opening',\n",
       " 'help',\n",
       " 'call',\n",
       " 'whirl',\n",
       " 'co-producer',\n",
       " 'non-binary',\n",
       " 'coexist',\n",
       " 'album—',\n",
       " 'set',\n",
       " 'torch',\n",
       " 'actually',\n",
       " 'Instead',\n",
       " 'animal',\n",
       " 'atmospheric',\n",
       " 'old',\n",
       " 'instantly',\n",
       " 'move',\n",
       " 'world',\n",
       " 'strip',\n",
       " 'biggest',\n",
       " 'even',\n",
       " 'leap',\n",
       " 'ever',\n",
       " 'free',\n",
       " 'first',\n",
       " 'forward',\n",
       " \"'m\",\n",
       " 'keep',\n",
       " 'also',\n",
       " 'opened',\n",
       " 'title',\n",
       " 'races.',\n",
       " 'writhing/Knuckled',\n",
       " 'different',\n",
       " 'sheen',\n",
       " 'normalize',\n",
       " 'want',\n",
       " 'made',\n",
       " 'trope',\n",
       " 'new',\n",
       " 'household',\n",
       " 'pain',\n",
       " 'answer',\n",
       " 'uniquely',\n",
       " 'lover',\n",
       " 'general',\n",
       " 'focused',\n",
       " 'profound',\n",
       " 'grief',\n",
       " 'self-destructive',\n",
       " 'get',\n",
       " 'female',\n",
       " 'tiny',\n",
       " 'go',\n",
       " 'scream',\n",
       " 'inadvertently',\n",
       " 'affecting',\n",
       " 'encapsulates',\n",
       " 'justified',\n",
       " 'grin',\n",
       " 'asks',\n",
       " 'evoking',\n",
       " 'digital',\n",
       " 'uncomfortably',\n",
       " 'grew',\n",
       " 'seeming',\n",
       " 'abusing',\n",
       " 'wish',\n",
       " 'turn',\n",
       " 'Out',\n",
       " 'told',\n",
       " 'grieving',\n",
       " 'diving',\n",
       " 'create',\n",
       " 'Philly',\n",
       " 'lost',\n",
       " 'mother',\n",
       " 'see',\n",
       " 'backed',\n",
       " 'Here',\n",
       " 'pairing',\n",
       " 'sure',\n",
       " 'repurposed',\n",
       " 'human',\n",
       " 'rooted',\n",
       " 'initial',\n",
       " 'largely',\n",
       " 'moving',\n",
       " 'Still',\n",
       " 'age-old',\n",
       " 'best',\n",
       " 'much',\n",
       " 'melancholic',\n",
       " 'unusual',\n",
       " 'look',\n",
       " 'driving',\n",
       " 'make',\n",
       " 'falling',\n",
       " 'strip-mall',\n",
       " 'simple',\n",
       " 'panned',\n",
       " 'never',\n",
       " 'Inspired',\n",
       " 'come',\n",
       " 'native',\n",
       " 'powerful',\n",
       " 'get',\n",
       " 'iconic',\n",
       " 'wanted',\n",
       " 'reminded',\n",
       " 'speaking',\n",
       " 'numerous',\n",
       " 'thread',\n",
       " 'began',\n",
       " 'sentiment',\n",
       " 'early',\n",
       " 'concept',\n",
       " 'often',\n",
       " 'personal',\n",
       " 'well',\n",
       " 'traditionally',\n",
       " 'said',\n",
       " 'sniffing',\n",
       " 'approach',\n",
       " 'empty',\n",
       " 'single',\n",
       " 'big',\n",
       " 'unpretentiously',\n",
       " 'interlude',\n",
       " 'raw',\n",
       " 'earlier',\n",
       " 'indie',\n",
       " 'pointedly',\n",
       " 'come',\n",
       " 'still',\n",
       " 'Then',\n",
       " 'flowing',\n",
       " 'newly-reunited',\n",
       " 'mourn',\n",
       " 'connecting',\n",
       " 'Boyish',\n",
       " 'rather',\n",
       " 'especially',\n",
       " 'always',\n",
       " 'metaphor']"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process(text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score_Binary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Inspired by the cosmos, Japanese Breakfast’s M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Alex Crossan’s debut album is a love letter to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>Featuring members of Merchandise, the Ukiah Dr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-18</th>\n",
       "      <td>With songs that travel great distances between...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-17</th>\n",
       "      <td>Held up by two good-to-great songs, the lightw...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Text  Score_Binary\n",
       "Date                                                                       \n",
       "2017-07-18  Inspired by the cosmos, Japanese Breakfast’s M...             1\n",
       "2017-07-18  Alex Crossan’s debut album is a love letter to...             1\n",
       "2017-07-18  Featuring members of Merchandise, the Ukiah Dr...             1\n",
       "2017-07-18  With songs that travel great distances between...             1\n",
       "2017-07-17  Held up by two good-to-great songs, the lightw...             1"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ad_nlp = df[['Text', 'Score_Binary']]\n",
    "ad_nlp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ad_nlp['Text'], ad_nlp['Score_Binary'], random_state=42, stratify=ad_nlp['Score_Binary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.to_frame()\n",
    "X_test = X_test.to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>The Brooklyn quartet Primitive Weapons blend t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-18</th>\n",
       "      <td>\"Live albums always offer a precarious task fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-22</th>\n",
       "      <td>What is the difference between American and It...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-03</th>\n",
       "      <td>I don't speak Norwegian very well. For this re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-07-27</th>\n",
       "      <td>Major label debut from these Swedish garage-ro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Text\n",
       "Date                                                         \n",
       "2016-04-22  The Brooklyn quartet Primitive Weapons blend t...\n",
       "2000-04-18  \"Live albums always offer a precarious task fo...\n",
       "2017-03-22  What is the difference between American and It...\n",
       "2002-12-03  I don't speak Norwegian very well. For this re...\n",
       "2004-07-27  Major label debut from these Swedish garage-ro..."
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-28</th>\n",
       "      <td>Flip through your calendars and count the days...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-27</th>\n",
       "      <td>Latest from the pop depressive is a sprawling,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-07-25</th>\n",
       "      <td>Self-proclaimed \"gypsy punks\" offer another di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-10-21</th>\n",
       "      <td>The 1980s legends continue their lengthy secon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-17</th>\n",
       "      <td>Frenchkiss, lately locating quality bands with...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Text\n",
       "Date                                                         \n",
       "2004-01-28  Flip through your calendars and count the days...\n",
       "2005-04-27  Latest from the pop depressive is a sprawling,...\n",
       "2007-07-25  Self-proclaimed \"gypsy punks\" offer another di...\n",
       "2009-10-21  The 1980s legends continue their lengthy secon...\n",
       "2010-03-17  Frenchkiss, lately locating quality bands with..."
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing all the text in the entire DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-04-22</th>\n",
       "      <td>The Brooklyn quartet Primitive Weapons blend t...</td>\n",
       "      <td>[mosh, pulse, touring, 'm, brain, Together, bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-18</th>\n",
       "      <td>\"Live albums always offer a precarious task fo...</td>\n",
       "      <td>[combine, Rocked, 'm, giant, mattered, nice, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-22</th>\n",
       "      <td>What is the difference between American and It...</td>\n",
       "      <td>[back, keying, celestial, musical, organ, rele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-12-03</th>\n",
       "      <td>I don't speak Norwegian very well. For this re...</td>\n",
       "      <td>[sound, 'm, path, cultural, yet, somewhat, far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-07-27</th>\n",
       "      <td>Major label debut from these Swedish garage-ro...</td>\n",
       "      <td>[Is, based, debut, clink, wily, yet, attitude,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Text  \\\n",
       "Date                                                            \n",
       "2016-04-22  The Brooklyn quartet Primitive Weapons blend t...   \n",
       "2000-04-18  \"Live albums always offer a precarious task fo...   \n",
       "2017-03-22  What is the difference between American and It...   \n",
       "2002-12-03  I don't speak Norwegian very well. For this re...   \n",
       "2004-07-27  Major label debut from these Swedish garage-ro...   \n",
       "\n",
       "                                               Text_Tokenized  \n",
       "Date                                                           \n",
       "2016-04-22  [mosh, pulse, touring, 'm, brain, Together, bo...  \n",
       "2000-04-18  [combine, Rocked, 'm, giant, mattered, nice, n...  \n",
       "2017-03-22  [back, keying, celestial, musical, organ, rele...  \n",
       "2002-12-03  [sound, 'm, path, cultural, yet, somewhat, far...  \n",
       "2004-07-27  [Is, based, debut, clink, wily, yet, attitude,...  "
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train['Text_Tokenized'] = X_train.Text.apply(process)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Text_Tokenized</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-01-28</th>\n",
       "      <td>Flip through your calendars and count the days...</td>\n",
       "      <td>[impressive, cleared, sometimes, recognizable,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005-04-27</th>\n",
       "      <td>Latest from the pop depressive is a sprawling,...</td>\n",
       "      <td>[thought, back, grant, dry, haunt, contagious,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-07-25</th>\n",
       "      <td>Self-proclaimed \"gypsy punks\" offer another di...</td>\n",
       "      <td>[somehow, distant, light, exceedingly, wear, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-10-21</th>\n",
       "      <td>The 1980s legends continue their lengthy secon...</td>\n",
       "      <td>[Do, punched, basically, motorcycle, two-word,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-17</th>\n",
       "      <td>Frenchkiss, lately locating quality bands with...</td>\n",
       "      <td>[stunted, wedge, somehow, winter, oft-repeated...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         Text  \\\n",
       "Date                                                            \n",
       "2004-01-28  Flip through your calendars and count the days...   \n",
       "2005-04-27  Latest from the pop depressive is a sprawling,...   \n",
       "2007-07-25  Self-proclaimed \"gypsy punks\" offer another di...   \n",
       "2009-10-21  The 1980s legends continue their lengthy secon...   \n",
       "2010-03-17  Frenchkiss, lately locating quality bands with...   \n",
       "\n",
       "                                               Text_Tokenized  \n",
       "Date                                                           \n",
       "2004-01-28  [impressive, cleared, sometimes, recognizable,...  \n",
       "2005-04-27  [thought, back, grant, dry, haunt, contagious,...  \n",
       "2007-07-25  [somehow, distant, light, exceedingly, wear, b...  \n",
       "2009-10-21  [Do, punched, basically, motorcycle, two-word,...  \n",
       "2010-03-17  [stunted, wedge, somehow, winter, oft-repeated...  "
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test['Text_Tokenized'] = X_test.Text.apply(process)\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting frequency estimates of the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for words in X_train.Text_Tokenized:\n",
    "    all_words += words\n",
    "    \n",
    "all_words = nltk.FreqDist(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'mosh': 19,\n",
       "          'pulse': 419,\n",
       "          'touring': 381,\n",
       "          \"'m\": 2440,\n",
       "          'brain': 15,\n",
       "          'Together': 98,\n",
       "          'bound': 64,\n",
       "          'however': 1399,\n",
       "          'express': 116,\n",
       "          'brooding': 211,\n",
       "          'self-titled': 640,\n",
       "          'musicians—knocking': 1,\n",
       "          'digital': 585,\n",
       "          'includes': 638,\n",
       "          'emphasized': 60,\n",
       "          'perhaps': 1478,\n",
       "          'groove': 646,\n",
       "          'shell': 25,\n",
       "          'act': 694,\n",
       "          'ran': 108,\n",
       "          'asking': 259,\n",
       "          'hurt': 193,\n",
       "          'album': 4613,\n",
       "          'trapped': 138,\n",
       "          'well': 3791,\n",
       "          'notably': 274,\n",
       "          'pressure-cooked': 1,\n",
       "          'great': 2568,\n",
       "          'breed': 35,\n",
       "          'years—as': 1,\n",
       "          'all-out': 25,\n",
       "          'perfectly': 952,\n",
       "          'flesh': 120,\n",
       "          'traditional': 898,\n",
       "          'repeating': 273,\n",
       "          'striking': 431,\n",
       "          'carving': 49,\n",
       "          'recording': 1505,\n",
       "          'spent': 532,\n",
       "          'quite': 2048,\n",
       "          'take': 4538,\n",
       "          'odd-metered': 7,\n",
       "          'empty': 397,\n",
       "          'varied': 361,\n",
       "          'straight-ahead': 64,\n",
       "          'renowned': 56,\n",
       "          'pattern': 331,\n",
       "          'shifting': 399,\n",
       "          'heavy': 1140,\n",
       "          'sound': 5823,\n",
       "          'second': 2815,\n",
       "          'atmosphere': 714,\n",
       "          'new': 5244,\n",
       "          'surprising': 589,\n",
       "          'global': 181,\n",
       "          'descending': 143,\n",
       "          'Steady': 34,\n",
       "          'third': 1282,\n",
       "          'steady': 541,\n",
       "          'drive': 222,\n",
       "          'last': 3916,\n",
       "          'song': 3433,\n",
       "          'raw': 631,\n",
       "          'local': 411,\n",
       "          'sings': 110,\n",
       "          'ear': 507,\n",
       "          'follows': 757,\n",
       "          'focus': 741,\n",
       "          'privacy': 4,\n",
       "          'venue': 50,\n",
       "          'entirely': 1066,\n",
       "          'earlier': 1050,\n",
       "          'locate': 31,\n",
       "          'human': 679,\n",
       "          'misidentified': 6,\n",
       "          'spooky': 90,\n",
       "          'broader': 138,\n",
       "          'formative': 108,\n",
       "          'chant': 135,\n",
       "          'much': 5940,\n",
       "          \"n't\": 7794,\n",
       "          'come': 5728,\n",
       "          'haunt': 35,\n",
       "          'deal': 177,\n",
       "          'think': 1840,\n",
       "          'collective': 498,\n",
       "          \"'re\": 4425,\n",
       "          'hot': 324,\n",
       "          'blend': 288,\n",
       "          'sharing': 139,\n",
       "          'leaving': 620,\n",
       "          'get': 4555,\n",
       "          'Perhaps': 699,\n",
       "          'riff': 564,\n",
       "          'lyrical': 987,\n",
       "          'speak': 179,\n",
       "          'scene': 164,\n",
       "          'cobra-like': 1,\n",
       "          'never': 4299,\n",
       "          'verse': 677,\n",
       "          'give': 2644,\n",
       "          'usual': 645,\n",
       "          'wave': 560,\n",
       "          'slew': 51,\n",
       "          'watched': 79,\n",
       "          'gamut': 34,\n",
       "          'left': 1622,\n",
       "          'le': 3144,\n",
       "          'fan': 325,\n",
       "          'Remains': 7,\n",
       "          'sophomore': 187,\n",
       "          'given': 1502,\n",
       "          'hulking': 19,\n",
       "          'footing': 55,\n",
       "          'alone': 1011,\n",
       "          'even': 6529,\n",
       "          'scope': 109,\n",
       "          'melodic': 1051,\n",
       "          'histrionic': 25,\n",
       "          'doomish': 2,\n",
       "          'calibrated': 20,\n",
       "          'combine': 87,\n",
       "          'Rocked': 1,\n",
       "          'giant': 119,\n",
       "          'mattered': 32,\n",
       "          'nice': 811,\n",
       "          'next': 1675,\n",
       "          'saw': 413,\n",
       "          'praise': 42,\n",
       "          'mean': 1339,\n",
       "          'also': 5048,\n",
       "          'cyclic': 6,\n",
       "          'extra': 424,\n",
       "          'Flavour': 1,\n",
       "          'summing': 18,\n",
       "          'later': 1677,\n",
       "          'leading': 348,\n",
       "          'stuff': 414,\n",
       "          'live': 2280,\n",
       "          'mostly': 1754,\n",
       "          'hook': 1038,\n",
       "          'tight': 469,\n",
       "          'crowd': 263,\n",
       "          'presumably': 243,\n",
       "          'guitar': 1616,\n",
       "          'offer': 552,\n",
       "          'Real': 115,\n",
       "          'review': 169,\n",
       "          'damn': 131,\n",
       "          'mesmerizing': 114,\n",
       "          'spell': 41,\n",
       "          'pictured': 21,\n",
       "          'splitting': 56,\n",
       "          'appeared': 399,\n",
       "          'hit': 1308,\n",
       "          'using': 807,\n",
       "          'want': 2235,\n",
       "          'little': 4009,\n",
       "          'fucking': 429,\n",
       "          'selection': 22,\n",
       "          'maybe': 1303,\n",
       "          'equally': 665,\n",
       "          'go': 3828,\n",
       "          'lack': 515,\n",
       "          'perfect': 996,\n",
       "          'Now': 1272,\n",
       "          'verbatim': 10,\n",
       "          'gut-punching': 6,\n",
       "          'previously': 629,\n",
       "          'impending': 89,\n",
       "          'cover': 783,\n",
       "          'undocumented': 6,\n",
       "          'passed': 294,\n",
       "          'see': 1804,\n",
       "          'close': 1466,\n",
       "          'Phish': 9,\n",
       "          'set': 2180,\n",
       "          'sinking': 65,\n",
       "          'twice': 256,\n",
       "          \"'ve\": 3597,\n",
       "          'right': 2145,\n",
       "          'actually': 2182,\n",
       "          'mom': 54,\n",
       "          'soloing': 97,\n",
       "          'know': 3151,\n",
       "          'ask': 219,\n",
       "          'stay': 349,\n",
       "          'largely': 897,\n",
       "          'alive': 340,\n",
       "          'exclaimed': 15,\n",
       "          'wound': 53,\n",
       "          'listing': 42,\n",
       "          'destruction': 7,\n",
       "          'called': 1558,\n",
       "          'restrained': 253,\n",
       "          'gathered': 89,\n",
       "          'resurfacing': 7,\n",
       "          'Alive': 24,\n",
       "          'unnecessary': 195,\n",
       "          'playing': 1663,\n",
       "          'Maybe': 406,\n",
       "          'recorded': 2053,\n",
       "          'exactly': 1367,\n",
       "          'merely': 552,\n",
       "          'rocked': 44,\n",
       "          'lurid': 22,\n",
       "          'seemed': 1102,\n",
       "          'say': 3265,\n",
       "          'straight': 758,\n",
       "          'too-perfect': 8,\n",
       "          'capturing': 145,\n",
       "          'Judging': 28,\n",
       "          'tune': 516,\n",
       "          'played': 1358,\n",
       "          'keeping': 525,\n",
       "          'standing': 245,\n",
       "          'knew': 355,\n",
       "          'belted': 17,\n",
       "          'light-speed': 10,\n",
       "          'precarious': 55,\n",
       "          'energized': 40,\n",
       "          'better': 2717,\n",
       "          'closing': 364,\n",
       "          'consider': 269,\n",
       "          'add': 1222,\n",
       "          'greatest': 638,\n",
       "          'Fucking': 31,\n",
       "          'track': 2848,\n",
       "          'probably': 1896,\n",
       "          'uh': 56,\n",
       "          'really': 3014,\n",
       "          'stage': 225,\n",
       "          'top': 695,\n",
       "          'always': 3223,\n",
       "          'subtle': 837,\n",
       "          'lot': 1307,\n",
       "          'end': 1558,\n",
       "          'ever': 2765,\n",
       "          'vibrato': 21,\n",
       "          'knowing': 277,\n",
       "          'captured': 203,\n",
       "          'lesser-known': 41,\n",
       "          'used': 1415,\n",
       "          'improv': 49,\n",
       "          'back': 4296,\n",
       "          'keying': 4,\n",
       "          'celestial': 83,\n",
       "          'musical': 2216,\n",
       "          'organ': 763,\n",
       "          'released': 2286,\n",
       "          'opening': 1393,\n",
       "          'carefully': 436,\n",
       "          'beatific': 31,\n",
       "          'make': 7711,\n",
       "          'violin': 160,\n",
       "          'finger': 46,\n",
       "          'start': 1386,\n",
       "          'meaning': 289,\n",
       "          'holding': 321,\n",
       "          'remarkable': 367,\n",
       "          'led': 417,\n",
       "          'marked': 377,\n",
       "          'label': 806,\n",
       "          'selling': 182,\n",
       "          'heard': 1005,\n",
       "          'duo': 476,\n",
       "          'key': 488,\n",
       "          'break': 632,\n",
       "          'impossible': 547,\n",
       "          'humming': 125,\n",
       "          'seventeen-minute': 1,\n",
       "          'appears': 578,\n",
       "          'peel': 14,\n",
       "          'stuck': 389,\n",
       "          'foray': 84,\n",
       "          'Motore': 1,\n",
       "          'American': 789,\n",
       "          'subliminal': 69,\n",
       "          'first': 6056,\n",
       "          'debut': 2005,\n",
       "          'explores': 97,\n",
       "          'piano': 559,\n",
       "          'burst': 263,\n",
       "          'attribute': 46,\n",
       "          'sustained': 206,\n",
       "          'preeminent': 12,\n",
       "          'producing': 238,\n",
       "          'breaking': 370,\n",
       "          'ascetic': 16,\n",
       "          'telling': 431,\n",
       "          'made': 3629,\n",
       "          'similar': 1348,\n",
       "          'diametrically': 11,\n",
       "          'stasis': 13,\n",
       "          'violinist': 20,\n",
       "          'work': 1476,\n",
       "          'impression': 18,\n",
       "          'brings': 313,\n",
       "          'hard': 2627,\n",
       "          'sought': 80,\n",
       "          'earliest': 263,\n",
       "          'wherein': 73,\n",
       "          'reissue': 116,\n",
       "          'contained': 235,\n",
       "          'op-art': 4,\n",
       "          'sparest': 14,\n",
       "          'Ever': 30,\n",
       "          'open': 1892,\n",
       "          'found': 1608,\n",
       "          'passing': 286,\n",
       "          'furious': 149,\n",
       "          'recent': 1753,\n",
       "          'soft': 653,\n",
       "          'settling': 178,\n",
       "          'latter': 878,\n",
       "          'alongside': 336,\n",
       "          'reissuing': 44,\n",
       "          'showcased': 97,\n",
       "          'ultimately': 958,\n",
       "          'concentration': 2,\n",
       "          'suspending': 5,\n",
       "          'sumptuous': 85,\n",
       "          'range': 257,\n",
       "          'minute': 265,\n",
       "          'mischievous': 49,\n",
       "          'continuum': 26,\n",
       "          'exquisitely': 65,\n",
       "          'gently': 433,\n",
       "          'collaborating': 85,\n",
       "          'spiritual': 383,\n",
       "          'continue': 369,\n",
       "          'originating': 8,\n",
       "          'greater': 422,\n",
       "          'mystic': 51,\n",
       "          'seems': 3403,\n",
       "          'microtonal': 20,\n",
       "          'release': 849,\n",
       "          'elsewhere': 357,\n",
       "          'long': 3043,\n",
       "          'late': 1234,\n",
       "          'simple': 1118,\n",
       "          'minimalist': 100,\n",
       "          'operatic': 104,\n",
       "          'delectable': 13,\n",
       "          'Italian': 88,\n",
       "          'extended': 544,\n",
       "          'fitting': 329,\n",
       "          'early': 2679,\n",
       "          'towering': 99,\n",
       "          'opposed': 150,\n",
       "          'slightly': 1134,\n",
       "          'wonder': 315,\n",
       "          'bow': 53,\n",
       "          'slow': 1090,\n",
       "          'suspended': 64,\n",
       "          'approach': 613,\n",
       "          'aural': 201,\n",
       "          'former': 1359,\n",
       "          'easily': 1133,\n",
       "          'resemble': 183,\n",
       "          'duomo': 1,\n",
       "          'assisted': 30,\n",
       "          'produced': 865,\n",
       "          'cascade': 34,\n",
       "          'still': 4796,\n",
       "          'unobtainable': 2,\n",
       "          'subtly': 351,\n",
       "          'pure': 241,\n",
       "          'held': 360,\n",
       "          'soon': 696,\n",
       "          'baganati': 1,\n",
       "          'revered': 73,\n",
       "          'rugged': 56,\n",
       "          'path': 115,\n",
       "          'cultural': 364,\n",
       "          'yet': 2793,\n",
       "          'somewhat': 733,\n",
       "          'far/': 1,\n",
       "          'pedigree': 60,\n",
       "          'possible': 759,\n",
       "          'chair/': 2,\n",
       "          'though': 188,\n",
       "          'caught': 274,\n",
       "          'curious': 386,\n",
       "          'performing': 187,\n",
       "          'forgive': 72,\n",
       "          'barrier': 16,\n",
       "          'employ': 172,\n",
       "          'scored': 120,\n",
       "          'elephant': 26,\n",
       "          'nicely': 452,\n",
       "          'understand/': 3,\n",
       "          'committed': 192,\n",
       "          'warble': 98,\n",
       "          'coupled': 113,\n",
       "          'poor': 232,\n",
       "          'doggy': 1,\n",
       "          'getting': 1409,\n",
       "          'normal': 110,\n",
       "          'vocal': 2698,\n",
       "          'bring': 504,\n",
       "          'likely': 1028,\n",
       "          'warmed': 24,\n",
       "          'top-ten': 2,\n",
       "          'apparently': 362,\n",
       "          'popular': 573,\n",
       "          'namely': 122,\n",
       "          'kitsch': 32,\n",
       "          'nonsense': 97,\n",
       "          'dream': 239,\n",
       "          'urgent': 178,\n",
       "          'horse': 12,\n",
       "          'sympathetic': 104,\n",
       "          'obviously': 447,\n",
       "          'tell': 626,\n",
       "          'paid': 196,\n",
       "          'got': 2331,\n",
       "          'else': 1654,\n",
       "          'prompted': 36,\n",
       "          'executed': 179,\n",
       "          'ill-equipped': 3,\n",
       "          'many': 3601,\n",
       "          'dense': 215,\n",
       "          'empathize': 10,\n",
       "          'blaze': 13,\n",
       "          'trying': 1670,\n",
       "          'barking': 49,\n",
       "          'harmonizing': 92,\n",
       "          'toiled': 13,\n",
       "          'uncanny': 171,\n",
       "          'cribbed': 38,\n",
       "          'critical': 349,\n",
       "          'exploited': 20,\n",
       "          'everywhere/': 5,\n",
       "          'apparent': 395,\n",
       "          'picked': 244,\n",
       "          'aping': 48,\n",
       "          'Rush-era': 1,\n",
       "          'Norwegian': 113,\n",
       "          'egregious': 48,\n",
       "          'opener': 594,\n",
       "          'distance/': 1,\n",
       "          'combined': 230,\n",
       "          'wit': 64,\n",
       "          'foot-stomping': 9,\n",
       "          'unremarkable': 99,\n",
       "          'now/': 20,\n",
       "          'decent': 244,\n",
       "          'modified': 37,\n",
       "          'clear': 1549,\n",
       "          'leave': 725,\n",
       "          'native': 271,\n",
       "          'worse/': 1,\n",
       "          'uniformly': 123,\n",
       "          'far': 2632,\n",
       "          'improves': 43,\n",
       "          'common': 614,\n",
       "          'determined': 142,\n",
       "          'falsetto': 264,\n",
       "          'campfire': 25,\n",
       "          'essense-of-Oldham': 1,\n",
       "          'Is': 1185,\n",
       "          'based': 455,\n",
       "          'clink': 4,\n",
       "          'wily': 34,\n",
       "          'attitude': 82,\n",
       "          'totally': 431,\n",
       "          'kept': 423,\n",
       "          'recall': 532,\n",
       "          'doll': 8,\n",
       "          'coat': 33,\n",
       "          'catchy': 227,\n",
       "          'writing': 855,\n",
       "          'scrappy': 120,\n",
       "          'lean': 392,\n",
       "          'done': 1205,\n",
       "          'proved': 245,\n",
       "          'appealing': 303,\n",
       "          'jab': 40,\n",
       "          'turn': 1836,\n",
       "          'windscreen': 1,\n",
       "          'incorporates': 59,\n",
       "          'kick': 370,\n",
       "          'expertly': 169,\n",
       "          'new-wave': 95,\n",
       "          'deep': 1068,\n",
       "          'told': 733,\n",
       "          'put': 1860,\n",
       "          'shake': 225,\n",
       "          'least': 2445,\n",
       "          'clenched': 32,\n",
       "          'strengthened': 14,\n",
       "          'balancing': 95,\n",
       "          'stepped': 82,\n",
       "          'trick': 199,\n",
       "          'thickheaded': 1,\n",
       "          'portrayed': 20,\n",
       "          'lead': 1038,\n",
       "          'searched': 9,\n",
       "          'gristle': 19,\n",
       "          'credit': 25,\n",
       "          'engaging': 432,\n",
       "          'petty': 48,\n",
       "          'sharp': 700,\n",
       "          'slight': 418,\n",
       "          '80s-drenched': 1,\n",
       "          'come-on': 38,\n",
       "          'answered': 60,\n",
       "          'strongest': 389,\n",
       "          'validation': 2,\n",
       "          'smudged': 18,\n",
       "          'stuffed': 125,\n",
       "          'combo': 44,\n",
       "          'swagger': 114,\n",
       "          'ballsy': 10,\n",
       "          'theft': 12,\n",
       "          'Swedish': 118,\n",
       "          'face': 325,\n",
       "          'legit': 31,\n",
       "          'quartet': 168,\n",
       "          'squad': 27,\n",
       "          'lineup': 140,\n",
       "          'big-time': 14,\n",
       "          'playin': 5,\n",
       "          'band': 3762,\n",
       "          \"puttin'-our-name-in-the-song\": 1,\n",
       "          'thumping': 96,\n",
       "          'backup': 62,\n",
       "          'newsboy': 1,\n",
       "          'turning': 580,\n",
       "          'old': 2269,\n",
       "          'Hives': 15,\n",
       "          'wall': 147,\n",
       "          'flailing': 51,\n",
       "          'concealed': 29,\n",
       "          'nexus': 21,\n",
       "          'tinkly': 16,\n",
       "          'sweat': 34,\n",
       "          'amalgam': 35,\n",
       "          'grudge-holding': 1,\n",
       "          'powerful': 634,\n",
       "          'forceful': 147,\n",
       "          'forget': 193,\n",
       "          'typically': 467,\n",
       "          'eagerness': 18,\n",
       "          'took': 955,\n",
       "          'boppy': 5,\n",
       "          'cleverly': 67,\n",
       "          'previous': 1353,\n",
       "          'guitarist': 428,\n",
       "          'hardened': 46,\n",
       "          'buzzing': 177,\n",
       "          'nowhere': 347,\n",
       "          'Where': 134,\n",
       "          'forcing': 96,\n",
       "          'justified': 29,\n",
       "          'artistic': 490,\n",
       "          'swing': 242,\n",
       "          'veering': 51,\n",
       "          'certain': 1048,\n",
       "          'pot': 30,\n",
       "          'friend': 527,\n",
       "          'happy': 503,\n",
       "          'reminding': 79,\n",
       "          'rewriting': 20,\n",
       "          'reboot': 9,\n",
       "          'subway': 43,\n",
       "          'persona': 168,\n",
       "          'wearisome': 7,\n",
       "          'said': 1594,\n",
       "          'lawn': 14,\n",
       "          'astronaut': 14,\n",
       "          'mowing': 5,\n",
       "          'wack': 7,\n",
       "          'call': 693,\n",
       "          'continues': 684,\n",
       "          'blaming': 8,\n",
       "          'public': 437,\n",
       "          'emcee': 36,\n",
       "          'announcing': 72,\n",
       "          'zeitgeist': 34,\n",
       "          'gothic': 178,\n",
       "          'important': 733,\n",
       "          'leftfield': 53,\n",
       "          'ridiculous': 276,\n",
       "          'rise': 195,\n",
       "          'name': 644,\n",
       "          'sub-sonically': 1,\n",
       "          'land': 98,\n",
       "          'cry': 177,\n",
       "          'rap': 335,\n",
       "          'sing-raps': 6,\n",
       "          'minor': 353,\n",
       "          'black': 814,\n",
       "          'best': 4634,\n",
       "          'drift': 217,\n",
       "          'Yawning': 2,\n",
       "          'sell': 265,\n",
       "          'loose': 685,\n",
       "          'die': 169,\n",
       "          'mere': 388,\n",
       "          'hot-air': 2,\n",
       "          'nitrate': 1,\n",
       "          'dangerously': 86,\n",
       "          'comparing': 70,\n",
       "          'lousy': 34,\n",
       "          'joint': 70,\n",
       "          'numbing': 44,\n",
       "          'useless': 47,\n",
       "          'self-introduction': 1,\n",
       "          'sod': 4,\n",
       "          'follow': 667,\n",
       "          'discouraged': 9,\n",
       "          'closer': 1381,\n",
       "          'wing': 30,\n",
       "          'twang-loving': 1,\n",
       "          'sometimes': 1624,\n",
       "          'softer': 92,\n",
       "          'suburban': 91,\n",
       "          'buoyancy': 3,\n",
       "          'time-lapsed': 3,\n",
       "          'glockenspiel': 34,\n",
       "          'disappearing': 66,\n",
       "          'yarn-spinning': 2,\n",
       "          'good-for-nothin': 1,\n",
       "          'wistful': 305,\n",
       "          'conflicting': 32,\n",
       "          'fearful': 12,\n",
       "          'sunset': 49,\n",
       "          'paint': 44,\n",
       "          'so-and-so': 1,\n",
       "          'sadness': 90,\n",
       "          'fiddle': 92,\n",
       "          'rollicking': 121,\n",
       "          'good': 3617,\n",
       "          'woodwind': 50,\n",
       "          'strange': 684,\n",
       "          'becomes': 508,\n",
       "          'throw': 232,\n",
       "          'jarring': 251,\n",
       "          'assume': 143,\n",
       "          'effortlessly': 268,\n",
       "          'ebb': 70,\n",
       "          'way/': 10,\n",
       "          'keep': 1452,\n",
       "          'slower': 216,\n",
       "          'remains': 970,\n",
       "          'tremble': 25,\n",
       "          'flying': 124,\n",
       "          'assuming': 82,\n",
       "          'relenting': 4,\n",
       "          'pedal': 189,\n",
       "          'one-scene': 1,\n",
       "          'dime': 33,\n",
       "          'remembered': 117,\n",
       "          'wounded': 103,\n",
       "          'keg': 7,\n",
       "          'traveler': 8,\n",
       "          'short': 1321,\n",
       "          'frequently': 487,\n",
       "          'walking': 218,\n",
       "          'arrival': 59,\n",
       "          'went': 863,\n",
       "          'Sally': 15,\n",
       "          'wet': 60,\n",
       "          'hymn-like': 11,\n",
       "          'hidden': 189,\n",
       "          'cinematic': 283,\n",
       "          'Indeed': 304,\n",
       "          'slammed': 17,\n",
       "          'listen': 1170,\n",
       "          'carrying': 137,\n",
       "          'confessing': 14,\n",
       "          'softly': 161,\n",
       "          'nearly': 1576,\n",
       "          'wrong': 625,\n",
       "          'conveying': 66,\n",
       "          'push': 275,\n",
       "          'going': 2115,\n",
       "          'playful': 427,\n",
       "          'lost': 1393,\n",
       "          'burgeoning': 78,\n",
       "          'making': 2237,\n",
       "          'twinkling': 135,\n",
       "          'countrypolitan': 11,\n",
       "          'Radio': 23,\n",
       "          'Strays': 2,\n",
       "          'respected': 57,\n",
       "          'belly-up': 1,\n",
       "          'tightly-blocked': 1,\n",
       "          'door': 54,\n",
       "          'emotional': 1184,\n",
       "          'able': 843,\n",
       "          'duet': 136,\n",
       "          'gorgeous': 729,\n",
       "          'curtain': 50,\n",
       "          'pristine': 65,\n",
       "          'beckoning': 17,\n",
       "          'Even': 1923,\n",
       "          'tawdry': 5,\n",
       "          'love': 1669,\n",
       "          'hope': 372,\n",
       "          'envious': 11,\n",
       "          'broken': 477,\n",
       "          'post-Dreamworks': 1,\n",
       "          'taunting': 37,\n",
       "          'lonely': 315,\n",
       "          'bleeding': 80,\n",
       "          'big': 1838,\n",
       "          'longer': 809,\n",
       "          'till': 25,\n",
       "          'solemnly': 19,\n",
       "          'lends': 212,\n",
       "          'bedding': 3,\n",
       "          'repeatedly': 207,\n",
       "          'vignette': 13,\n",
       "          'sung': 190,\n",
       "          'bleak': 181,\n",
       "          'justify': 54,\n",
       "          'dusting': 19,\n",
       "          'Equally': 13,\n",
       "          'evident': 256,\n",
       "          'So': 904,\n",
       "          'placed': 276,\n",
       "          'comforting': 143,\n",
       "          'dancing': 270,\n",
       "          'alternative': 203,\n",
       "          'light': 949,\n",
       "          'festival': 111,\n",
       "          'existed': 153,\n",
       "          'faintly': 102,\n",
       "          'Swirled': 1,\n",
       "          'whistle': 80,\n",
       "          'electro': 206,\n",
       "          'major': 777,\n",
       "          'washed': 56,\n",
       "          'begin': 963,\n",
       "          'blue': 322,\n",
       "          'acoustic': 1911,\n",
       "          'came': 1378,\n",
       "          'flute-and-cello': 1,\n",
       "          'returning': 245,\n",
       "          'bolt': 17,\n",
       "          'sought-after': 5,\n",
       "          'two-minute': 156,\n",
       "          'trigger': 15,\n",
       "          'Attic': 12,\n",
       "          'late-': 28,\n",
       "          'Instead': 1043,\n",
       "          'secret': 271,\n",
       "          'chapter-like': 2,\n",
       "          'side': 703,\n",
       "          'ser': 1,\n",
       "          'sent': 155,\n",
       "          'Argonautes': 1,\n",
       "          'interested': 483,\n",
       "          'vocoder-like': 2,\n",
       "          'enough': 3344,\n",
       "          'overall': 538,\n",
       "          'listening': 1292,\n",
       "          'choppy': 92,\n",
       "          'un': 12,\n",
       "          'electronic': 1612,\n",
       "          'piano-led': 31,\n",
       "          'island-hopping': 2,\n",
       "          'processed': 239,\n",
       "          'ever-expanding': 21,\n",
       "          'utilizing': 52,\n",
       "          'confusing': 103,\n",
       "          'dictated': 20,\n",
       "          'unexpected': 544,\n",
       "          'lengthy': 233,\n",
       "          'essential': 462,\n",
       "          'contrapuntal': 14,\n",
       "          'classical': 355,\n",
       "          'quest': 122,\n",
       "          'widely': 165,\n",
       "          'beautiful': 740,\n",
       "          'arrangement': 189,\n",
       "          'painting': 113,\n",
       "          'brought': 525,\n",
       "          'exception': 33,\n",
       "          'private-press': 4,\n",
       "          'various': 688,\n",
       "          'sidestepping': 11,\n",
       "          'jibing': 3,\n",
       "          'limited': 487,\n",
       "          'minimalism': 89,\n",
       "          'spun': 59,\n",
       "          'rising': 260,\n",
       "          'tumbling': 107,\n",
       "          'dynamic': 647,\n",
       "          'frame': 85,\n",
       "          'impressionistic': 130,\n",
       "          'bottle': 65,\n",
       "          'amb': 1,\n",
       "          'sleek': 142,\n",
       "          'visual': 245,\n",
       "          'presenting': 111,\n",
       "          'Spend': 6,\n",
       "          'almost': 3329,\n",
       "          'challenge': 98,\n",
       "          'Greek': 25,\n",
       "          'aka': 146,\n",
       "          'mind': 321,\n",
       "          'reciting': 28,\n",
       "          'accompanied': 225,\n",
       "          'narrative': 766,\n",
       "          'emphasizes': 121,\n",
       "          'strangeness': 23,\n",
       "          'historical': 157,\n",
       "          'particularly': 1239,\n",
       "          'run': 1087,\n",
       "          'creating': 588,\n",
       "          'fittingly': 87,\n",
       "          'balanced': 148,\n",
       "          'l': 6,\n",
       "          'dark': 773,\n",
       "          'stem': 69,\n",
       "          'passage—not': 1,\n",
       "          're-launching': 1,\n",
       "          'anti-capitalism': 2,\n",
       "          'east': 29,\n",
       "          'moving': 870,\n",
       "          'unusual': 310,\n",
       "          'requires': 170,\n",
       "          'unearthing': 21,\n",
       "          'standalone': 15,\n",
       "          'individually': 57,\n",
       "          'cut': 980,\n",
       "          'tacking': 11,\n",
       "          'progressive': 170,\n",
       "          'save': 335,\n",
       "          'began': 645,\n",
       "          'fine': 796,\n",
       "          'performed': 359,\n",
       "          'orient': 4,\n",
       "          'spoken': 257,\n",
       "          'taxonomical': 6,\n",
       "          'message': 95,\n",
       "          'Iberian': 3,\n",
       "          'head-on': 22,\n",
       "          'whole': 1897,\n",
       "          'growing': 449,\n",
       "          'futuristic': 136,\n",
       "          'lens': 79,\n",
       "          'language': 23,\n",
       "          'flute': 207,\n",
       "          'chanted—infused': 1,\n",
       "          '’': 1010,\n",
       "          'final': 1242,\n",
       "          'strong': 1157,\n",
       "          'lie': 438,\n",
       "          'sailing': 27,\n",
       "          'liquefied': 10,\n",
       "          'ensemble': 265,\n",
       "          'compositional': 179,\n",
       "          'swirling': 223,\n",
       "          'oceanic': 43,\n",
       "          'psychedelic': 493,\n",
       "          'drifting': 226,\n",
       "          'bookended': 48,\n",
       "          'contemporary': 615,\n",
       "          'opposite': 360,\n",
       "          'chanted': 37,\n",
       "          'pointed': 212,\n",
       "          'musician': 657,\n",
       "          'Spanish': 134,\n",
       "          'atlas': 1,\n",
       "          'marimba': 28,\n",
       "          'bowed': 73,\n",
       "          'proto-punk': 20,\n",
       "          'imprint': 64,\n",
       "          'plucking': 82,\n",
       "          'sufficiently': 42,\n",
       "          'ominous': 408,\n",
       "          'playtime': 4,\n",
       "          'signee': 14,\n",
       "          'politicking': 10,\n",
       "          'grime-oriented': 1,\n",
       "          'map': 72,\n",
       "          'uniting': 17,\n",
       "          'juvenilia': 7,\n",
       "          'injected': 27,\n",
       "          'politically': 86,\n",
       "          'apocalyptic': 185,\n",
       "          'increasingly': 553,\n",
       "          'label/collective': 2,\n",
       "          'joining': 73,\n",
       "          'parallel': 119,\n",
       "          'equivalent': 225,\n",
       "          'aesthetic': 1136,\n",
       "          'documentary': 144,\n",
       "          'sonic': 1142,\n",
       "          'Ma-ness': 1,\n",
       "          'Spawned': 2,\n",
       "          'uncanniness': 2,\n",
       "          'crumbling': 49,\n",
       "          'attempted': 188,\n",
       "          'expect': 814,\n",
       "          'piling': 64,\n",
       "          'surprisingly': 709,\n",
       "          'compliment': 49,\n",
       "          'rarely': 842,\n",
       "          'molasses': 10,\n",
       "          'join': 114,\n",
       "          'maintain': 114,\n",
       "          'committing': 45,\n",
       "          'Re-Entry': 1,\n",
       "          'beat': 1758,\n",
       "          'notoriously': 80,\n",
       "          'forward-thinking': 50,\n",
       "          'arpeggiated': 72,\n",
       "          'evolved': 151,\n",
       "          'occult': 14,\n",
       "          'prosed': 1,\n",
       "          'fictional': 67,\n",
       "          'pours': 18,\n",
       "          'political': 472,\n",
       "          'uncategorizable': 9,\n",
       "          'capable': 575,\n",
       "          'danceable': 138,\n",
       "          'attached': 104,\n",
       "          'described': 392,\n",
       "          'noise': 1214,\n",
       "          'chilly': 153,\n",
       "          'metal': 279,\n",
       "          'adopted': 107,\n",
       "          'wish': 441,\n",
       "          'sculptural': 10,\n",
       "          'emoji': 5,\n",
       "          'current': 730,\n",
       "          'necromancer': 1,\n",
       "          'synths': 552,\n",
       "          'analgesic': 3,\n",
       "          'nightmare': 59,\n",
       "          'unpredictable': 268,\n",
       "          'process': 179,\n",
       "          'unofficial': 36,\n",
       "          'technocratic': 2,\n",
       "          'grim': 168,\n",
       "          'actual': 728,\n",
       "          'unfurl': 35,\n",
       "          'runtime': 88,\n",
       "          'showing': 263,\n",
       "          'industrial': 355,\n",
       "          'endless': 234,\n",
       "          'itself—scarily': 1,\n",
       "          'website': 137,\n",
       "          'often': 3427,\n",
       "          'interesting': 1305,\n",
       "          'bonfire': 7,\n",
       "          'pop': 1188,\n",
       "          'alien': 175,\n",
       "          'lose': 328,\n",
       "          'pound': 23,\n",
       "          'describe': 123,\n",
       "          'twisted': 203,\n",
       "          'artist': 963,\n",
       "          'intellectual': 108,\n",
       "          'single': 2788,\n",
       "          'military': 75,\n",
       "          'caustic': 112,\n",
       "          'use': 431,\n",
       "          'York/London': 1,\n",
       "          'founding': 105,\n",
       "          'unabashedly': 117,\n",
       "          'net-art': 1,\n",
       "          'playfulness': 63,\n",
       "          'London-based': 45,\n",
       "          'supposed': 450,\n",
       "          'drum': 810,\n",
       "          'Then': 876,\n",
       "          'middle': 780,\n",
       "          'singular': 341,\n",
       "          'choose': 137,\n",
       "          'fully': 907,\n",
       "          'skip': 78,\n",
       "          'rave': 165,\n",
       "          'rather': 2327,\n",
       "          'penchant': 127,\n",
       "          'technically': 177,\n",
       "          'cold': 400,\n",
       "          'trappish': 1,\n",
       "          'rehashing': 30,\n",
       "          'fairly': 494,\n",
       "          'indifferent': 26,\n",
       "          'titled': 564,\n",
       "          'seamlessly': 220,\n",
       "          'tourist': 4,\n",
       "          'classic': 1400,\n",
       "          'Free': 79,\n",
       "          'garbled': 56,\n",
       "          'bad': 1301,\n",
       "          'laundry': 33,\n",
       "          'legendary': 249,\n",
       "          'crossing': 71,\n",
       "          'fuck': 374,\n",
       "          'entire': 957,\n",
       "          '*lying': 1,\n",
       "          ...})"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procuring the n-most important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_important_features(all_words, n=3000):\n",
    "    sred = sorted(all_words.items(), key=lambda x : x[1])\n",
    "    sred = sred[::-1]\n",
    "\n",
    "    word_features = [word.lower() for (word, count) in sred[:n]]\n",
    "\n",
    "    return word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features = get_important_features(all_words, n=4000)\n",
    "len(word_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import pickle\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function I created to calculate ROC-AUC Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_roc_auc_score(model):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    \n",
    "    dists = model.prob_classify_many([features[0] for features in test_set])\n",
    "    probs = [[dist.prob(0), dist.prob(1)] for dist in dists]\n",
    "    \n",
    "    probs_neg = [item[0] for item in probs]\n",
    "    probs_pos = [item[1] for item in probs]\n",
    "    \n",
    "    actual = [features[1] for features in test_set]\n",
    "    \n",
    "    print(\"ROC-AUC Score: \", roc_auc_score(actual, probs_pos) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function I created to easily pickle models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pickle_it(model, model_name):\n",
    "    import pickle\n",
    "    save_model = open(model_name + '.pickle', 'wb')\n",
    "    pickle.dump(model, save_model)\n",
    "    save_model.close()\n",
    "    \n",
    "def open_jar(model_name):\n",
    "    import pickle\n",
    "    model_file = open(model_name + '.pickle', 'rb')\n",
    "    model = pickle.load(model_file)\n",
    "    model_file.close()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A helper function I created to make train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(x, word_features):\n",
    "    words = set(x)\n",
    "    \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features[word] = (word in words)\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a train and test set for model building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"n't\",\n",
       " 'make',\n",
       " 'even',\n",
       " 'first',\n",
       " 'much',\n",
       " 'sound',\n",
       " 'come',\n",
       " 'new',\n",
       " 'also',\n",
       " 'still',\n",
       " 'best',\n",
       " 'album',\n",
       " 'get',\n",
       " 'take',\n",
       " \"'re\",\n",
       " 'never',\n",
       " 'back',\n",
       " 'little',\n",
       " 'last',\n",
       " 'go',\n",
       " 'well',\n",
       " 'band',\n",
       " 'made',\n",
       " 'good',\n",
       " 'many',\n",
       " \"'ve\",\n",
       " 'song',\n",
       " 'often',\n",
       " 'seems',\n",
       " 'enough',\n",
       " 'almost',\n",
       " 'say',\n",
       " 'always',\n",
       " 'know',\n",
       " 'le',\n",
       " 'long',\n",
       " 'really',\n",
       " 'track',\n",
       " 'second',\n",
       " 'yet',\n",
       " 'single',\n",
       " 'ever',\n",
       " 'better',\n",
       " 'vocal',\n",
       " 'early',\n",
       " 'find',\n",
       " 'give',\n",
       " 'far',\n",
       " 'hard',\n",
       " 'seem',\n",
       " 'great',\n",
       " 'together',\n",
       " 'least',\n",
       " \"'m\",\n",
       " 'away',\n",
       " 'got',\n",
       " 'rather',\n",
       " 'released',\n",
       " 'live',\n",
       " 'old',\n",
       " 'making',\n",
       " 'want',\n",
       " 'musical',\n",
       " 'actually',\n",
       " 'set',\n",
       " 'right',\n",
       " 'feel',\n",
       " 'going',\n",
       " 'different',\n",
       " 'full',\n",
       " 'recorded',\n",
       " 'quite',\n",
       " 'debut',\n",
       " 'pretty',\n",
       " 'even',\n",
       " 'acoustic',\n",
       " 'whole',\n",
       " 'probably',\n",
       " 'open',\n",
       " 'put',\n",
       " 'think',\n",
       " 'big',\n",
       " 'turn',\n",
       " 'real',\n",
       " 'see',\n",
       " 'instead',\n",
       " 'especially',\n",
       " 'already',\n",
       " 'beat',\n",
       " 'easy',\n",
       " 'mostly',\n",
       " 'recent',\n",
       " 'hear',\n",
       " 'later',\n",
       " 'next',\n",
       " 'trying',\n",
       " 'love',\n",
       " 'playing',\n",
       " 'else',\n",
       " 'sometimes',\n",
       " 'left',\n",
       " 'guitar',\n",
       " 'electronic',\n",
       " 'found',\n",
       " 'said',\n",
       " 'high',\n",
       " 'original',\n",
       " 'nearly',\n",
       " 'instrumental',\n",
       " 'end',\n",
       " 'called',\n",
       " 'clear',\n",
       " 'simply',\n",
       " 'not',\n",
       " 'recording',\n",
       " 'given',\n",
       " 'perhaps',\n",
       " 'play',\n",
       " 'work',\n",
       " 'close',\n",
       " 'still',\n",
       " 'keep',\n",
       " 'latest',\n",
       " 'familiar',\n",
       " 'here',\n",
       " 'used',\n",
       " 'getting',\n",
       " 'classic',\n",
       " 'however',\n",
       " 'lost',\n",
       " 'opening',\n",
       " 'start',\n",
       " 'closer',\n",
       " 'came',\n",
       " 'exactly',\n",
       " 'former',\n",
       " 'played',\n",
       " 'previous',\n",
       " 'similar',\n",
       " 'mean',\n",
       " 'title',\n",
       " 'short',\n",
       " 'hit',\n",
       " 'singing',\n",
       " 'lot',\n",
       " 'interesting',\n",
       " 'maybe',\n",
       " 'bad',\n",
       " 'listening',\n",
       " 'full-length',\n",
       " 'third',\n",
       " 'true',\n",
       " 'now',\n",
       " 'become',\n",
       " 'final',\n",
       " 'particularly',\n",
       " 'late',\n",
       " 'songwriting',\n",
       " 'add',\n",
       " 'finally',\n",
       " 'noise',\n",
       " 'certainly',\n",
       " 'done',\n",
       " 'pop',\n",
       " 'several',\n",
       " 'working',\n",
       " 'is',\n",
       " 'show',\n",
       " 'emotional',\n",
       " 'listen',\n",
       " 'synth',\n",
       " 'strong',\n",
       " 'rhythm',\n",
       " 'occasionally',\n",
       " 'young',\n",
       " 'sonic',\n",
       " 'heavy',\n",
       " 'aesthetic',\n",
       " 'slightly',\n",
       " 'easily',\n",
       " 'small',\n",
       " 'simple',\n",
       " 'coming',\n",
       " 'personal',\n",
       " 'seemed',\n",
       " 'solo',\n",
       " 'slow',\n",
       " 'obvious',\n",
       " 'run',\n",
       " 'indie',\n",
       " 'taking',\n",
       " 'completely',\n",
       " 'deep',\n",
       " 'including',\n",
       " 'entirely',\n",
       " 'need',\n",
       " 'melodic',\n",
       " 'earlier',\n",
       " 'certain',\n",
       " 'known',\n",
       " 'instead',\n",
       " 'lead',\n",
       " 'hook',\n",
       " 'likely',\n",
       " 'alone',\n",
       " '’',\n",
       " 'heard',\n",
       " 'perfect',\n",
       " 'particular',\n",
       " 'let',\n",
       " 'lyrical',\n",
       " 'difficult',\n",
       " 'cut',\n",
       " 'taken',\n",
       " 'feeling',\n",
       " 'built',\n",
       " 'remains',\n",
       " 'sure',\n",
       " 'artist',\n",
       " 'begin',\n",
       " 'ultimately',\n",
       " 'entire',\n",
       " 'took',\n",
       " 'perfectly',\n",
       " 'light',\n",
       " 'felt',\n",
       " 'bit',\n",
       " 'fully',\n",
       " 'so',\n",
       " 'inspired',\n",
       " 'sounded',\n",
       " 'traditional',\n",
       " 'largely',\n",
       " 'past',\n",
       " 'written',\n",
       " 'clearly',\n",
       " 'latter',\n",
       " 'electric',\n",
       " 'then',\n",
       " 'sounding',\n",
       " 'moving',\n",
       " 'modern',\n",
       " 'free',\n",
       " 'produced',\n",
       " 'went',\n",
       " 'quickly',\n",
       " 'writing',\n",
       " 'release',\n",
       " 'able',\n",
       " 'barely',\n",
       " 'hold',\n",
       " 'rarely',\n",
       " 'gone',\n",
       " 'subtle',\n",
       " 'somewhere',\n",
       " 'looking',\n",
       " 'mix',\n",
       " 'otherwise',\n",
       " 'usually',\n",
       " 'following',\n",
       " 'expect',\n",
       " 'black',\n",
       " 'complete',\n",
       " 'nice',\n",
       " 'drum',\n",
       " 'longer',\n",
       " 'using',\n",
       " 'label',\n",
       " 'turned',\n",
       " 'thought',\n",
       " 'giving',\n",
       " 'fine',\n",
       " 'string',\n",
       " 'immediately',\n",
       " 'american',\n",
       " 'started',\n",
       " 'cover',\n",
       " 'eventually',\n",
       " 'middle',\n",
       " 'major',\n",
       " 'dark',\n",
       " 'recently',\n",
       " 'impressive',\n",
       " 'more',\n",
       " 'narrative',\n",
       " 'organ',\n",
       " 'featuring',\n",
       " 'solid',\n",
       " 'possible',\n",
       " 'straight',\n",
       " 'follows',\n",
       " 'slowly',\n",
       " 'seemingly',\n",
       " 'worked',\n",
       " 'focus',\n",
       " 'beautiful',\n",
       " 'important',\n",
       " 'told',\n",
       " 'somewhat',\n",
       " 'current',\n",
       " 'natural',\n",
       " 'gorgeous',\n",
       " 'actual',\n",
       " 'present',\n",
       " 'leave',\n",
       " 'beginning',\n",
       " 'ago',\n",
       " 'experimental',\n",
       " 'seen',\n",
       " 'atmosphere',\n",
       " 'forward',\n",
       " 'stand',\n",
       " 'surprisingly',\n",
       " 'became',\n",
       " 'fit',\n",
       " 'side',\n",
       " 'similarly',\n",
       " 'sharp',\n",
       " 'perhaps',\n",
       " 'soon',\n",
       " 'top',\n",
       " 'truly',\n",
       " 'rare',\n",
       " 'act',\n",
       " 'call',\n",
       " 'rock',\n",
       " 'various',\n",
       " 'quiet',\n",
       " 'loose',\n",
       " 'strange',\n",
       " 'continues',\n",
       " 'occasional',\n",
       " 'followed',\n",
       " 'human',\n",
       " 'rhythmic',\n",
       " 'low',\n",
       " 'verse',\n",
       " 'sing',\n",
       " 'follow',\n",
       " 'piece',\n",
       " 'biggest',\n",
       " 'equally',\n",
       " 'musician',\n",
       " 'hip-hop',\n",
       " 'creative',\n",
       " 'worth',\n",
       " 'relatively',\n",
       " 'named',\n",
       " 'soft',\n",
       " 'backing',\n",
       " 'hardly',\n",
       " 'excellent',\n",
       " 'genre',\n",
       " 'form',\n",
       " 'dynamic',\n",
       " 'talking',\n",
       " 'groove',\n",
       " 'began',\n",
       " 'usual',\n",
       " 'name',\n",
       " 'heavily',\n",
       " 'self-titled',\n",
       " 'white',\n",
       " 'greatest',\n",
       " 'includes',\n",
       " 'favorite',\n",
       " 'rich',\n",
       " 'powerful',\n",
       " 'wrote',\n",
       " 'break',\n",
       " 'raw',\n",
       " 'setting',\n",
       " 'previously',\n",
       " 'tell',\n",
       " 'look',\n",
       " 'wrong',\n",
       " 'romantic',\n",
       " 'write',\n",
       " 'leaving',\n",
       " 'last',\n",
       " 'contemporary',\n",
       " 'unique',\n",
       " 'common',\n",
       " 'do',\n",
       " 'approach',\n",
       " 'carry',\n",
       " 'complex',\n",
       " 'warm',\n",
       " 'aside',\n",
       " 'included',\n",
       " 'read',\n",
       " 'direct',\n",
       " 'running',\n",
       " 'opener',\n",
       " 'memorable',\n",
       " 'lo-fi',\n",
       " 'provides',\n",
       " 'surprising',\n",
       " 'feature',\n",
       " 'however',\n",
       " 'creating',\n",
       " 'potential',\n",
       " 'ballad',\n",
       " 'british',\n",
       " 'weird',\n",
       " 'digital',\n",
       " 'subject',\n",
       " 'sort',\n",
       " 'large',\n",
       " 'adding',\n",
       " 'suggests',\n",
       " 'chorus',\n",
       " 'serious',\n",
       " 'turning',\n",
       " 'generally',\n",
       " 'dead',\n",
       " 'appears',\n",
       " 'disc',\n",
       " 'distorted',\n",
       " 'guest',\n",
       " 'capable',\n",
       " 'popular',\n",
       " 'due',\n",
       " 'proper',\n",
       " 'necessarily',\n",
       " 'main',\n",
       " 'apart',\n",
       " 'bright',\n",
       " 'wanted',\n",
       " 'titled',\n",
       " 'riff',\n",
       " 'wave',\n",
       " 'piano',\n",
       " 'focused',\n",
       " 'sweet',\n",
       " 'general',\n",
       " 'filled',\n",
       " 'gave',\n",
       " 'cool',\n",
       " 'increasingly',\n",
       " 'synths',\n",
       " 'merely',\n",
       " 'offer',\n",
       " 'impossible',\n",
       " 'draw',\n",
       " 'unexpected',\n",
       " 'extended',\n",
       " 'welcome',\n",
       " 'art',\n",
       " 'voice',\n",
       " 'only',\n",
       " 'believe',\n",
       " 'fresh',\n",
       " 'steady',\n",
       " 'touch',\n",
       " 'flow',\n",
       " 'overall',\n",
       " 'created',\n",
       " 'saying',\n",
       " 'dramatic',\n",
       " 'recall',\n",
       " 'spent',\n",
       " 'essentially',\n",
       " 'most',\n",
       " 'compelling',\n",
       " 'follow-up',\n",
       " 'horn',\n",
       " 'friend',\n",
       " 'lyric',\n",
       " 'brought',\n",
       " 'keeping',\n",
       " 'successful',\n",
       " 'suggest',\n",
       " 'ambitious',\n",
       " 'worse',\n",
       " 'tune',\n",
       " 'lack',\n",
       " 'move',\n",
       " 'minimal',\n",
       " 'huge',\n",
       " 'becomes',\n",
       " 'fall',\n",
       " 'ear',\n",
       " 'possibly',\n",
       " 'static',\n",
       " 'stylistic',\n",
       " 'fourth',\n",
       " 'bring',\n",
       " 'comfortable',\n",
       " 'happy',\n",
       " 'considered',\n",
       " 'appear',\n",
       " 'mixed',\n",
       " 'collective',\n",
       " 'clean',\n",
       " 'fairly',\n",
       " 'commercial',\n",
       " 'thinking',\n",
       " 'psychedelic',\n",
       " 'changed',\n",
       " 'originally',\n",
       " 'suddenly',\n",
       " 'artistic',\n",
       " 'na',\n",
       " 'echo',\n",
       " 'effective',\n",
       " 'drumming',\n",
       " 'key',\n",
       " 'limited',\n",
       " 'frequently',\n",
       " 'somehow',\n",
       " 'interested',\n",
       " 'distinct',\n",
       " 'rest',\n",
       " 'accessible',\n",
       " 'considering',\n",
       " 'broken',\n",
       " 'basic',\n",
       " 'directly',\n",
       " 'duo',\n",
       " 'shift',\n",
       " 'political',\n",
       " 'guy',\n",
       " 'helped',\n",
       " 'build',\n",
       " 'material',\n",
       " 'tight',\n",
       " 'typically',\n",
       " 'loop',\n",
       " 'stop',\n",
       " 'anthem',\n",
       " 'funny',\n",
       " 'along',\n",
       " '”',\n",
       " 'constantly',\n",
       " 'essential',\n",
       " 'finding',\n",
       " 'starting',\n",
       " 'becoming',\n",
       " 'worst',\n",
       " 'managed',\n",
       " 'help',\n",
       " 'reminiscent',\n",
       " 'individual',\n",
       " 'based',\n",
       " 'living',\n",
       " 'driving',\n",
       " 'nicely',\n",
       " 'delivered',\n",
       " 'supposed',\n",
       " 'consistent',\n",
       " 'odd',\n",
       " 'growing',\n",
       " 'missing',\n",
       " 'bigger',\n",
       " 'obviously',\n",
       " 'pushing',\n",
       " 'sample',\n",
       " 'double',\n",
       " 'distant',\n",
       " 'brief',\n",
       " 'wide',\n",
       " 'wish',\n",
       " 'equal',\n",
       " 'letting',\n",
       " 'lie',\n",
       " 'public',\n",
       " 'oddly',\n",
       " 'consistently',\n",
       " 'vaguely',\n",
       " 'carefully',\n",
       " 'lovely',\n",
       " 'change',\n",
       " 'orchestral',\n",
       " 'basically',\n",
       " 'added',\n",
       " 'underground',\n",
       " 'return',\n",
       " 'gently',\n",
       " 'engaging',\n",
       " 'compared',\n",
       " 'fellow',\n",
       " 'use',\n",
       " 'totally',\n",
       " 'telling',\n",
       " 'striking',\n",
       " 'massive',\n",
       " 'unfortunately',\n",
       " 'initially',\n",
       " 'fucking',\n",
       " 'typical',\n",
       " 'context',\n",
       " 'guitarist',\n",
       " 'putting',\n",
       " 'playful',\n",
       " 'practically',\n",
       " 'other',\n",
       " 'grand',\n",
       " 'hypnotic',\n",
       " 'listener',\n",
       " '“',\n",
       " 'extra',\n",
       " 'outside',\n",
       " 'necessary',\n",
       " 'kept',\n",
       " 'future',\n",
       " 'greater',\n",
       " 'point',\n",
       " 'pulse',\n",
       " 'established',\n",
       " 'slight',\n",
       " 'quietly',\n",
       " 'funk',\n",
       " 'tough',\n",
       " 'led',\n",
       " 'moved',\n",
       " 'ambient',\n",
       " 'musically',\n",
       " 'remember',\n",
       " 'calling',\n",
       " 'falling',\n",
       " 'remain',\n",
       " 'stuff',\n",
       " 'busy',\n",
       " 'closest',\n",
       " 'featured',\n",
       " 'saw',\n",
       " 'tone',\n",
       " 'imagine',\n",
       " 'highly',\n",
       " 'local',\n",
       " 'leaf',\n",
       " 'defined',\n",
       " 'ready',\n",
       " 'available',\n",
       " 'quick',\n",
       " 'sad',\n",
       " 'gentle',\n",
       " 'couple',\n",
       " 'much',\n",
       " 'ominous',\n",
       " 'offering',\n",
       " 'gradually',\n",
       " 'specific',\n",
       " 'definitely',\n",
       " 'maybe',\n",
       " 'flat',\n",
       " 'shit',\n",
       " 'famous',\n",
       " 'create',\n",
       " 'aforementioned',\n",
       " 'hearing',\n",
       " 'unlikely',\n",
       " 'tried',\n",
       " 'plenty',\n",
       " 'cold',\n",
       " 'spare',\n",
       " 'appeared',\n",
       " 'shifting',\n",
       " 'central',\n",
       " 'releasing',\n",
       " 'exciting',\n",
       " 'empty',\n",
       " 'meant',\n",
       " 'apparent',\n",
       " 'described',\n",
       " 'lean',\n",
       " 'attempt',\n",
       " 'seriously',\n",
       " 'expected',\n",
       " 'atmospheric',\n",
       " 'strongest',\n",
       " 'stuck',\n",
       " 'realized',\n",
       " 'waiting',\n",
       " 'constant',\n",
       " 'mere',\n",
       " 'curious',\n",
       " 'melancholy',\n",
       " 'happened',\n",
       " 'tiny',\n",
       " 'finest',\n",
       " 'repetitive',\n",
       " 'pair',\n",
       " 'spiritual',\n",
       " 'older',\n",
       " 'happens',\n",
       " 'like',\n",
       " 'layered',\n",
       " 'enjoyable',\n",
       " 'deeply',\n",
       " 'nostalgia',\n",
       " 'post-punk',\n",
       " 'muted',\n",
       " 'touring',\n",
       " 'repeated',\n",
       " 'front',\n",
       " 'anyway',\n",
       " 'casual',\n",
       " 'reach',\n",
       " 'intriguing',\n",
       " 'closely',\n",
       " 'understated',\n",
       " 'needed',\n",
       " 'career',\n",
       " 'marked',\n",
       " 'formed',\n",
       " 'loud',\n",
       " 'special',\n",
       " 'handful',\n",
       " 'highlight',\n",
       " 'pull',\n",
       " 'fuck',\n",
       " 'pleasant',\n",
       " 'charming',\n",
       " 'aggressive',\n",
       " 'hope',\n",
       " 'initial',\n",
       " 'prof',\n",
       " 'kick',\n",
       " 'breaking',\n",
       " 'immediate',\n",
       " 'continue',\n",
       " 'percussive',\n",
       " 'watching',\n",
       " 'organic',\n",
       " 'simultaneously',\n",
       " 'remarkable',\n",
       " 'affecting',\n",
       " 'try',\n",
       " 'ahead',\n",
       " 'physical',\n",
       " 'cultural',\n",
       " 'closing',\n",
       " 'confident',\n",
       " 'singer',\n",
       " 'apparently',\n",
       " 'thin',\n",
       " 'record',\n",
       " 'varied',\n",
       " 'brilliant',\n",
       " 'opposite',\n",
       " 'held',\n",
       " 'stick',\n",
       " 'performed',\n",
       " 'grown',\n",
       " 'cast',\n",
       " 'dropped',\n",
       " 'elsewhere',\n",
       " 'meanwhile',\n",
       " 'ending',\n",
       " 'industrial',\n",
       " 'classical',\n",
       " 'knew',\n",
       " 'naturally',\n",
       " 'minor',\n",
       " 'larger',\n",
       " 'subtly',\n",
       " 'star',\n",
       " 'tired',\n",
       " 'critical',\n",
       " 'stay',\n",
       " 'instantly',\n",
       " 'punk',\n",
       " 'leading',\n",
       " 'thick',\n",
       " 'fair',\n",
       " 'fast',\n",
       " 'nowhere',\n",
       " 'cohesive',\n",
       " 'tend',\n",
       " 'forced',\n",
       " 'beautifully',\n",
       " 'willing',\n",
       " 'indeed',\n",
       " 'haunting',\n",
       " 'vibe',\n",
       " 'include',\n",
       " 'emotionally',\n",
       " 'singular',\n",
       " 'intense',\n",
       " 'alive',\n",
       " 'resulting',\n",
       " 'total',\n",
       " 'female',\n",
       " 'weight',\n",
       " 'half',\n",
       " 'extreme',\n",
       " 'intended',\n",
       " 'wild',\n",
       " 'buried',\n",
       " 'born',\n",
       " 'video',\n",
       " 'tour',\n",
       " 'served',\n",
       " 'alongside',\n",
       " 'allowing',\n",
       " 'distinctive',\n",
       " 'save',\n",
       " 'rap',\n",
       " 'earnest',\n",
       " 'dry',\n",
       " 'designed',\n",
       " 'concerned',\n",
       " 'social',\n",
       " 'modest',\n",
       " 'fill',\n",
       " 'arguably',\n",
       " 'provide',\n",
       " 'covered',\n",
       " 'pattern',\n",
       " 'stunning',\n",
       " 'deeper',\n",
       " 'delicate',\n",
       " 'smart',\n",
       " 'serve',\n",
       " 'conventional',\n",
       " 'fitting',\n",
       " 'drawing',\n",
       " 'happen',\n",
       " 'lose',\n",
       " 'strangely',\n",
       " 'bassist',\n",
       " 'lush',\n",
       " 'tempo',\n",
       " 'absolutely',\n",
       " 'face',\n",
       " 'fan',\n",
       " 'literally',\n",
       " 'lay',\n",
       " 'promising',\n",
       " 'hot',\n",
       " 'sitting',\n",
       " 'french',\n",
       " 'manages',\n",
       " 'blue',\n",
       " 'mind',\n",
       " 'holding',\n",
       " 'separate',\n",
       " 'composed',\n",
       " 'out',\n",
       " 'folk',\n",
       " 'us',\n",
       " 'decided',\n",
       " 'silly',\n",
       " 'allows',\n",
       " 'shared',\n",
       " 'losing',\n",
       " 'crucial',\n",
       " 'lonely',\n",
       " 'wonder',\n",
       " 'expansive',\n",
       " 'place',\n",
       " 'result',\n",
       " 'vocalist',\n",
       " 'brings',\n",
       " 'effectively',\n",
       " 'pulled',\n",
       " 'pushed',\n",
       " 'anthemic',\n",
       " 'mixing',\n",
       " 'echoing',\n",
       " 'unusual',\n",
       " 'abstract',\n",
       " 'fascinating',\n",
       " 'anywhere',\n",
       " 'awkward',\n",
       " 'decidedly',\n",
       " 'technical',\n",
       " 'evocative',\n",
       " 'worthy',\n",
       " 'primary',\n",
       " 'outfit',\n",
       " 'wistful',\n",
       " 'recognizable',\n",
       " 'melody',\n",
       " 'higher',\n",
       " 'indeed',\n",
       " 'shimmering',\n",
       " 'learned',\n",
       " 'multiple',\n",
       " 'appealing',\n",
       " 'remarkably',\n",
       " 'developed',\n",
       " 'purpose',\n",
       " 'safe',\n",
       " 'fantastic',\n",
       " 'appropriate',\n",
       " 'exist',\n",
       " 'produce',\n",
       " 'spend',\n",
       " 'accomplished',\n",
       " 'vast',\n",
       " 'grew',\n",
       " 'tribute',\n",
       " 'involved',\n",
       " 'presented',\n",
       " 'lyrically',\n",
       " 'offered',\n",
       " 'rolling',\n",
       " 'straightforward',\n",
       " 'primarily',\n",
       " 'perspective',\n",
       " 'fun',\n",
       " 'concept',\n",
       " 'prior',\n",
       " 'rendered',\n",
       " 'relative',\n",
       " 'passed',\n",
       " 'sampled',\n",
       " 'up',\n",
       " 'note',\n",
       " 'subdued',\n",
       " 'sudden',\n",
       " 'replaced',\n",
       " 'realize',\n",
       " 'drummer',\n",
       " 'crafted',\n",
       " 'allowed',\n",
       " 'cheap',\n",
       " 'unreleased',\n",
       " 'evoke',\n",
       " 'cutting',\n",
       " 'met',\n",
       " 'meaning',\n",
       " 'ended',\n",
       " 'failed',\n",
       " 'level',\n",
       " 'blend',\n",
       " 'rapper',\n",
       " 'frontman',\n",
       " 'joined',\n",
       " 'floating',\n",
       " 'passing',\n",
       " 'notable',\n",
       " 'earned',\n",
       " 'seeing',\n",
       " 'thrilling',\n",
       " 'removed',\n",
       " 'cinematic',\n",
       " 'rapping',\n",
       " 'inevitable',\n",
       " 'longtime',\n",
       " 'provided',\n",
       " 'boy',\n",
       " 'utterly',\n",
       " 'complicated',\n",
       " 'bold',\n",
       " 'satisfying',\n",
       " 'epic',\n",
       " 'red',\n",
       " 'providing',\n",
       " 'forever',\n",
       " 'overwhelming',\n",
       " 'good',\n",
       " 'predictable',\n",
       " 'metal',\n",
       " 'nostalgic',\n",
       " 'loved',\n",
       " 'remix',\n",
       " 'missed',\n",
       " 'standard',\n",
       " 'knowing',\n",
       " 'placed',\n",
       " 'ridiculous',\n",
       " 'listened',\n",
       " 'girl',\n",
       " 'contains',\n",
       " 'adventurous',\n",
       " 'push',\n",
       " 'surely',\n",
       " 'bringing',\n",
       " 'easier',\n",
       " 'bear',\n",
       " 'caught',\n",
       " 'notably',\n",
       " 'inside',\n",
       " 'vague',\n",
       " 'extremely',\n",
       " 'repeating',\n",
       " 'significant',\n",
       " 'sweeping',\n",
       " 'laid',\n",
       " 'conceptual',\n",
       " 'elegant',\n",
       " 'picking',\n",
       " 'exploring',\n",
       " 'secret',\n",
       " 'native',\n",
       " 'overly',\n",
       " 'dancing',\n",
       " 'boring',\n",
       " 'universe',\n",
       " 'smooth',\n",
       " 'life',\n",
       " 'consider',\n",
       " 'anymore',\n",
       " 'remaining',\n",
       " 'unpredictable',\n",
       " 'effortlessly',\n",
       " ...]"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = [(find_features(tokens, word_features), cat) for tokens, cat in zip(X_train.Text_Tokenized, y_train)]\n",
    "test_set = [(find_features(tokens, word_features), cat) for tokens, cat in zip(X_test.Text_Tokenized, y_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_bayes_classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK Naive Bayes Accuracy: 86.3021420519 %\n"
     ]
    }
   ],
   "source": [
    "print('NLTK Naive Bayes Accuracy:', nltk.classify.accuracy(naive_bayes_classifier, test_set) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC Score:  86.60786765 %\n"
     ]
    }
   ],
   "source": [
    "get_roc_auc_score(naive_bayes_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                 stately = True                1 : 0      =      9.9 : 1.0\n",
      "              controlled = True                1 : 0      =      8.5 : 1.0\n",
      "                 pulsing = True                1 : 0      =      7.8 : 1.0\n",
      "              channeling = True                1 : 0      =      6.6 : 1.0\n",
      "                spectral = True                1 : 0      =      6.5 : 1.0\n",
      "              seamlessly = True                1 : 0      =      6.2 : 1.0\n",
      "                 cracked = True                1 : 0      =      6.2 : 1.0\n",
      "          characteristic = True                1 : 0      =      6.1 : 1.0\n",
      "               sustained = True                1 : 0      =      5.8 : 1.0\n",
      "                passable = True                0 : 1      =      5.7 : 1.0\n",
      "              emphasizes = True                1 : 0      =      5.7 : 1.0\n",
      "              rollicking = True                1 : 0      =      5.7 : 1.0\n",
      "              fluttering = True                1 : 0      =      5.6 : 1.0\n",
      "                    suck = True                0 : 1      =      5.5 : 1.0\n",
      "               insistent = True                1 : 0      =      5.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "naive_bayes_classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_it(naive_bayes_classifier, 'naive_bayes_classifier')\n",
    "naive_bayes_classifier = open_jar('naive_bayes_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<SklearnClassifier(MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))>"
      ]
     },
     "execution_count": 608,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNB = SklearnClassifier(MultinomialNB())\n",
    "MNB.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes Accuracy: 87.6832018038 %\n"
     ]
    }
   ],
   "source": [
    "print('Multinomial Naive Bayes Accuracy:', nltk.classify.accuracy(MNB, test_set) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_roc_auc_score(MNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_it(MNB, 'mnb_classifier')\n",
    "MNB = open_jar('mnb_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BNB = SklearnClassifier(BernoulliNB())\n",
    "BNB.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Bernoulli Naive Bayes Accuracy:', nltk.classify.accuracy(BNB, test_set) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_roc_auc_score(BNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_it(BNB, 'bnb_classifier')\n",
    "BNB = open_jar('bnb_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = SklearnClassifier(LogisticRegression())\n",
    "logistic.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Logistic Regression Accuracy:', nltk.classify.accuracy(logistic, test_set) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_roc_auc_score(logistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_it(logistic, 'logistic_classifier')\n",
    "logistic = open_jar('logistic_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SGD = SklearnClassifier(SGDClassifier())\n",
    "SGD.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Stochastic Gradient Descent Accuracy:', nltk.classify.accuracy(SGD, test_set) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_roc_auc_score(SGD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_it(SGD, 'sgd_classifier')\n",
    "SGD = open_jar('sgd_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vectors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC = SklearnClassifier(SVC())\n",
    "SVC.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Support Vector Classifier Accuracy:', nltk.classify.accuracy(SVC, test_set) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_roc_auc_score(SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_it(SVC, 'svc_classifier')\n",
    "SVC = open_jar('svc_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Support Vectors Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSVC = SklearnClassifier(LinearSVC())\n",
    "LSVC.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Linear Support Vector Classifier Accuracy:', nltk.classify.accuracy(LSVC, test_set) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_roc_auc_score(LSVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_it(LSVC, 'lsvc_classifier')\n",
    "LSVC = open_jar('lsvc_classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VoteClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, I plan to aggregate my multiple models in order to have a robust ensemble method. The idea behind this is that even if it mildly hurts my accuracy, it improves my ROC-AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.classify import ClassifierI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VoteClassifier(ClassifierI):\n",
    "    \n",
    "    def __init__(self, *classifiers):\n",
    "        self.classifiers = classifiers\n",
    "    \n",
    "    def classify(self, features):\n",
    "        from statistics import mode\n",
    "        votes = [model.classify(features) for model in self.classifiers]\n",
    "        return mode(votes)\n",
    "    \n",
    "    def confidence(self, features):\n",
    "        from statistics import mode\n",
    "        votes = [model.classify(features) for model in self.classifiers]\n",
    "        \n",
    "        choice_votes = votes.count(mode.votes)\n",
    "        confidence = choice_votes / len(votes)\n",
    "        \n",
    "        return confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voted_classifier = VoteClassifier(naive_bayes_classifier, MNB, logistic, SGD, SVC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Voted Classifier Accuracy:', nltk.classify.accuracy(voted_classifier, test_set) * 100, '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
